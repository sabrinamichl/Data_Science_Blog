{
  "hash": "732d7883fcf598de69c6b49119c327aa",
  "result": {
    "markdown": "---\ntitle: \"Text Mining Solution\"\nauthor: \"Sabrina Michl\"\ndate: \"2023-01-31\"\ncategories: [code, analysis]\nbibliography: ref.bib\nimage: \"image_solution.png\"\n---\n\n\n# 1. Preliminary Note & Definition\n\n## 1.1 Preliminary Note\n\nFor this analysis we use the dataset from @data/0B5VML_2019 out of the zip archive @data/0B5VML/XIUWJ7_2019. The data are licensed according to Attribution 4.0 International (CC-BY-4.0).\n\nThe welcome page picture, to this post is from <a href=\"https://pixabay.com/de/users/talhakhalil007-5671515/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=4271251\">talha khalil</a> at <a href=\"https://pixabay.com/de//?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=4271251\">Pixabay</a>\n\n## 1.2 Definition of Hate Speech\n\nThe [United Nations](https://www.un.org/en/hate-speech/understanding-hate-speech/what-is-hate-speech) defines hate speech as: \"***any kind of communication** in speech, writing or behaviour, that **attacks** or uses **pejorative** or **discriminatory** language with reference to a person or a group on the basis of **who they are**, in other words, based on their religion, ethnicity, nationality, race, colour, descent, gender or other identity factor.\"*\n\nThe problem about hate speech is, that there is no universal definition that can be used.\n\nSo our research question is, if there is any possibility to predict hate speech by using tweets and how well is the prediction?\n\n# 2. Load The Packages\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(rio)\nlibrary(tidymodels)\nlibrary(tidytext)\nlibrary(textrecipes)\nlibrary(lsa)\nlibrary(discrim)\nlibrary(naivebayes)\nlibrary(tictoc)\nlibrary(fastrtext)\nlibrary(remoji)\nlibrary(tokenizers)\n```\n:::\n\n\n# 3. Load Dataset And Minor Changes\n\n## 3.1 Train Dataset\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd_train <- read_tsv(\"C:/Users/sapi-/OneDrive/Studium/5. Semester/Data Science II/Data_Science_Blog/daten/germeval2018.training.txt\", col_names = FALSE)\n```\n:::\n\n\n### Rename Columns\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnames(d_train) <- c(\"text\", \"c1\", \"c2\")\n```\n:::\n\n\n### Add ID Column\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd_train <- d_train %>%\nmutate(id = row_number()) %>%\nselect(id, everything())\n```\n:::\n\n\n## 3.2 Test Dataset\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd_test <- read_tsv(\"C:/Users/sapi-/OneDrive/Studium/5. Semester/Data Science II/Data_Science_Blog/daten/germeval2018.test.txt\", col_names = FALSE)\n```\n:::\n\n\n### Rename Columns\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnames(d_test) <- c(\"text\", \"c1\", \"c2\")\n```\n:::\n\n\n### Add ID Column\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd_test <- d_test %>%\nmutate(id = row_number()) %>%\nselect(id, everything())\n```\n:::\n\n\n# 4. Insert The Predefined Word Embedding List\n\nThe used word embeddings are from @grave2018learning. The data are licensed according to Attribution-ShareAlike 3.0 Unported (CC-BY-SA 3.0).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nout_file_model <- \"C:/Users/sapi-/OneDrive - Hochschule fÃ¼r Angewandte Wissenschaften Ansbach/Desktop/AWM/angewandte Wirtschats- und Medienpsychologie/5. Semester/Word_Embedding/de.300.bin\"\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfile.exists(out_file_model)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] TRUE\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfasttext_model <- load_model(out_file_model)\ndictionary <- get_dictionary(fasttext_model)\nget_word_vectors(fasttext_model, c(\"menschen\")) %>% `[`(1:10)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] -0.043737594 -0.033647023 -0.016398411  0.037433818  0.029863771\n [6] -0.008217440  0.002691153 -0.027484305 -0.058012061  0.004103063\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nprint(head(dictionary, 10))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] \",\"    \".\"    \"</s>\" \"und\"  \"der\"  \":\"    \"die\"  \"\\\"\"   \")\"    \"(\"   \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nword_embedding_text <- tibble(word = dictionary)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\noptions(mc.cores = parallel::detectCores())\nwords_vecs <- get_word_vectors(fasttext_model)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nword_embedding_text <-\nword_embedding_text %>%\nbind_cols(words_vecs)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nnames(word_embedding_text) <- c(\"word\", paste0(\"v\", sprintf(\"%03d\", 1:301)))\n```\n:::\n\n\n# 5. Insert The Helperfunctions\n\nWe are using the package [pradadata](https://github.com/sebastiansauer/pradadata) by @sebastian_sauer_2018_1996614. The data are licensed according to General Public License 3 (GLP-3).\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(\"schimpwoerter\", package = \"pradadata\")\ndata(\"sentiws\", package = \"pradadata\")\ndata(\"wild_emojis\", package = \"pradadata\")\nsource(\"C:/Users/sapi-/OneDrive/Studium/5. Semester/Data Science II/Data_Science_Blog/helper/helper_funs.R\")\n```\n:::\n\n\n# 6. Define Recipe - rec4 - TF-IDF\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrec4 <-\nrecipe(c1 ~., data = select(d_train, text, c1, id)) %>%\nupdate_role(id, new_role = \"id\") %>% \nstep_text_normalization(text) %>%\nstep_mutate(emo_count = map_int(text, ~count_lexicon(.x, sentiws$word))) %>%\nstep_mutate(schimpf_count = map_int(text, ~count_lexicon(.x, schimpfwoerter$word))) %>%\nstep_mutate(wild_emojis = map_int(text, ~count_lexicon(.x, wild_emojis$emoji))) %>%\nstep_mutate(text_copy = text) %>%\nstep_textfeature(text_copy) %>%\nstep_tokenize(text) %>%\nstep_stopwords(text, language = \"de\", stopword_source = \"snowball\") %>%\nstep_stem(text) %>%\nstep_tfidf(text)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nrec4_prep <- rec4 %>%\nprep() %>%\nrecipes::bake(new_data = NULL)\n```\n:::\n\n\n# 7. Build Resamples\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfolds <- vfold_cv(data = d_train,\nv = 3,\nrepeats = 2,\nstrata = c1)\n```\n:::\n\n\n# 8. Build the Penalty-Grid\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlambda_grid <- grid_regular(penalty(), levels = 25)\n```\n:::\n\n\n# 9. Lasso-L1 With TF-IDF\n\nWe take only the best model from the [analysis](https://world-of-datascience.netlify.app/posts/text-mining_new/).\n\n### L1-Model\n\n\n::: {.cell}\n\n```{.r .cell-code}\nl1_86_mod <- logistic_reg(penalty = tune(), mixture = 1) %>%\nset_engine(\"glmnet\") %>%\nset_mode(\"classification\")\nl1_86_mod\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLogistic Regression Model Specification (classification)\n\nMain Arguments:\n  penalty = tune()\n  mixture = 1\n\nComputational engine: glmnet \n```\n:::\n:::\n\n\n### Define The Workflow\n\n\n::: {.cell}\n\n```{.r .cell-code}\nl1_86_wf <-workflow() %>%\nadd_recipe(rec4) %>%\nadd_model(l1_86_mod)\nl1_86_wf\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n== Workflow ====================================================================\nPreprocessor: Recipe\nModel: logistic_reg()\n\n-- Preprocessor ----------------------------------------------------------------\n10 Recipe Steps\n\n* step_text_normalization()\n* step_mutate()\n* step_mutate()\n* step_mutate()\n* step_mutate()\n* step_textfeature()\n* step_tokenize()\n* step_stopwords()\n* step_stem()\n* step_tfidf()\n\n-- Model -----------------------------------------------------------------------\nLogistic Regression Model Specification (classification)\n\nMain Arguments:\n  penalty = tune()\n  mixture = 1\n\nComputational engine: glmnet \n```\n:::\n:::\n\n\n### Resampling & Model Quality\n\n\n::: {.cell}\n\n```{.r .cell-code}\noptions(mc.cores = parallel::detectCores())\nl1_86_wf_fit <- tune_grid(\nl1_86_wf,\nfolds,\ngrid = lambda_grid,\ncontrol = control_resamples(save_pred = TRUE)\n)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Paket 'stringi' wurde unter R Version 4.1.2 erstellt\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Paket 'textfeatures' wurde unter R Version 4.1.3 erstellt\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Paket 'stopwords' wurde unter R Version 4.1.3 erstellt\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Paket 'glmnet' wurde unter R Version 4.1.3 erstellt\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Paket 'Matrix' wurde unter R Version 4.1.3 erstellt\n```\n:::\n:::\n\n\n### Model Performance\n\n\n::: {.cell}\n\n```{.r .cell-code}\nl1_86_wf_performance <- collect_metrics(l1_86_wf_fit)\nl1_86_wf_performance\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 50 x 7\n    penalty .metric  .estimator  mean     n std_err .config              \n      <dbl> <chr>    <chr>      <dbl> <int>   <dbl> <chr>                \n 1 1   e-10 accuracy binary     0.746     6 0.00212 Preprocessor1_Model01\n 2 1   e-10 roc_auc  binary     0.776     6 0.00266 Preprocessor1_Model01\n 3 2.61e-10 accuracy binary     0.746     6 0.00212 Preprocessor1_Model02\n 4 2.61e-10 roc_auc  binary     0.776     6 0.00266 Preprocessor1_Model02\n 5 6.81e-10 accuracy binary     0.746     6 0.00212 Preprocessor1_Model03\n 6 6.81e-10 roc_auc  binary     0.776     6 0.00266 Preprocessor1_Model03\n 7 1.78e- 9 accuracy binary     0.746     6 0.00212 Preprocessor1_Model04\n 8 1.78e- 9 roc_auc  binary     0.776     6 0.00266 Preprocessor1_Model04\n 9 4.64e- 9 accuracy binary     0.746     6 0.00212 Preprocessor1_Model05\n10 4.64e- 9 roc_auc  binary     0.776     6 0.00266 Preprocessor1_Model05\n# ... with 40 more rows\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nl1_86_wf_fit_preds <- collect_predictions(l1_86_wf_fit)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nl1_86_wf_fit_preds %>% \n  group_by(id) %>% \n  roc_curve(truth = c1, .pred_OFFENSE) %>% \n  autoplot()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-26-1.png){width=672}\n:::\n:::\n\n\n### Select The Best\n\n\n::: {.cell}\n\n```{.r .cell-code}\nchosen_auc_l1_86_wf_fit <-\nl1_86_wf_fit %>%\nselect_by_one_std_err(metric = \"roc_auc\", -penalty)\nchosen_auc_l1_86_wf_fit\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 x 9\n  penalty .metric .estimator  mean     n std_err .config            .best .bound\n    <dbl> <chr>   <chr>      <dbl> <int>   <dbl> <chr>              <dbl>  <dbl>\n1 0.00825 roc_auc binary     0.787     6 0.00502 Preprocessor1_Mod~ 0.787  0.782\n```\n:::\n:::\n\n\n# 10. Predictions\n\n## Finalize The Workflow\n\n\n::: {.cell}\n\n```{.r .cell-code}\nl1_86_wf_final <- \n  l1_86_wf %>% \n  finalize_workflow(select_best(l1_86_wf_fit, metric = \"roc_auc\"))\n```\n:::\n\n\n## Adaptation Of The Finished Workflow To The Training Dataset\n\n\n::: {.cell}\n\n```{.r .cell-code}\noptions(mc.cores = parallel::detectCores())\nfit_train <- l1_86_wf_final %>% \n  fit(d_train)\n```\n:::\n\n\n## Adapt The Predictions To The Test Dataset\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit_test <- fit_train %>% \n  predict(d_test)\n```\n:::\n\n\n# 11. Check The Predictions\n\n## Add ID Column\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit_test <- fit_test %>% \n  mutate(id = row_number())\n```\n:::\n\n\n## Join Both Datasets\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntest <- fit_test %>% \n  full_join(d_test, by = \"id\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntest <- test %>% \n  select(id, text, c1, c2, .pred_class)\n```\n:::\n\n\n## Test The Predictions\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntest %>% \n  count(c1, .pred_class)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 4 x 3\n  c1      .pred_class     n\n  <chr>   <fct>       <int>\n1 OFFENSE OFFENSE       237\n2 OFFENSE OTHER         521\n3 OTHER   OFFENSE       113\n4 OTHER   OTHER        1357\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntest %>% \n  filter(c1 == \"OTHER\", .pred_class == \"OTHER\") %>% \n  nrow/nrow(test)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.6090664\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntest %>% \n  filter(c1 == \"OFFENSE\", .pred_class == \"OFFENSE\") %>% \n  nrow/nrow(test)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.1063734\n```\n:::\n:::\n\n\n> The table shows us how the predictions `.pred_class` match the actual classified data `c1`.\n>\n> So we see, that 237 OFFENSE (10,6 %) tweets are actually predicted to be OFFENSE and that 1357 (60,9 %) OTHER classified tweets are predicted to be OTHER.\n>\n> Only 634 tweets were not predicted correctly.\n\nAccuracy\n\n\n::: {.cell}\n\n```{.r .cell-code}\naccuracy(test, truth = factor(c1), estimate = .pred_class)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 x 3\n  .metric  .estimator .estimate\n  <chr>    <chr>          <dbl>\n1 accuracy binary         0.715\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsens(test, truth = factor(c1), estimate = .pred_class)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 x 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 sens    binary         0.313\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nspec(test, truth = factor(c1), estimate = .pred_class)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 x 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 spec    binary         0.923\n```\n:::\n:::\n\n\n# 12. Research Question\n\nNow we have to clear the research question, it there is any possibility to predict hate speech by using tweets and how well is the prediction?\n\n1.  Yes, we can predict hate speech with tweets!\n2.  The accuracy (71,5 %) shows us, how well the prediction is!\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}