---
title: "Text Mining Analysis"
author: "Sabrina Michl"
date: "2023-01-30"
categories: [code, analysis]
bibliography: ref.bib
image: "image.jpg"
---

# 1. Preliminary Note & Definition

## 1.1 Preliminary Note

For this analysis we use the dataset from @data/0B5VML_2019 out of the zip archive @data/0B5VML/XIUWJ7_2019. The data are licensed according to Attribution 4.0 International (CC-BY-4.0).

The picture to this post from the welcome page, is from <a href="https://pixabay.com/de/users/geralt-9301/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=7691355">Gerd Altmann</a> at <a href="https://pixabay.com/de//?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=7691355">Pixabay</a>

## 1.2 Definition of Hate Speech

@un defines hate speech as: "***any kind of communication** in speech, writing or behaviour, that **attacks** or uses **pejorative** or **discriminatory** language with reference to a person or a group on the basis of **who they are**, in other words, based on their religion, ethnicity, nationality, race, colour, descent, gender or other identity factor."*

The problem about hate speech is, that there is no universal definition that can be used.

So our research question is, if there is any possibility to predict hate speech by using tweets and how well is the prediction?

# 2. Load The Packages

```{r output=FALSE}
library(tidyverse)
library(rio)
library(tidymodels)
library(tidytext)
library(textrecipes)
library(lsa)
library(discrim)
library(naivebayes)
library(tictoc)
library(fastrtext)
library(remoji)
library(tokenizers)
```

# 3. Load Dataset And Minor Changes

## 3.1 Train Dataset

```{r output=FALSE}
d_train <- read_tsv("C:/Users/sapi-/OneDrive/Studium/5. Semester/Data Science II/Data_Science_Blog/daten/germeval2018.training.txt", col_names = FALSE)
```

### Rename Columns

```{r}
names(d_train) <- c("text", "c1", "c2")
```

### Add ID Column

```{r}
d_train <- d_train %>%
mutate(id = row_number()) %>%
select(id, everything())
```

# 4. Explore Dataset

```{r}
train_toc <- d_train %>%
unnest_tokens(output = token, input = text)
train_toc
```

> First tokenize the dataset d_train.

## 4.1 Insert `Stopwords_de`

```{r}
data(stopwords_de, package = "lsa")
stopwords_de <- tibble(word = stopwords_de)
stopwords_de <- stopwords_de %>%
rename(token = word)
```

> After that we use the stopwords_de to `anti_join` this with train_toc dataset.

```{r}
train_toc2 <- train_toc %>%
anti_join(stopwords_de)
```

## Show The Important Words

```{r}
train_toc2 <- train_toc2 %>%
count(token, sort = TRUE)
```

### Plot

```{r}
train_toc2 %>%
slice_head(n=20) %>%
ggplot()+
aes(y=reorder(factor(token), n), x = n, color = token)+
geom_col(aes(fill = token, alpha = 2.5)) +
ggtitle("The Most Used Words") +
ylab("Token")+
xlab("Quantity")+
theme_minimal()+
theme(legend.position = "none")
```

> We see that the most used word is "lbr". We could inspect the dataset way deeper, e.g. do a manual sentimentanalysis, do a lemmatization or stem the words. But we will have a look at these processes in the different machine learning algorithms following now.

# 5. Preparation

## 5.1 Define Recipe - rec1 - TF-IDF

```{r}
rec1 <-
recipe(c1 ~ ., data = select(d_train, text, c1, id)) %>%
update_role(id, new_role = "id") %>%
step_tokenize(text) %>%
step_stopwords(text, language = "de", stopword_source = "snowball") %>%
step_stem(text) %>%
step_tfidf(text) %>%
step_normalize(all_numeric_predictors())
rec1
```

### Prep & Bake - rec1

```{r}
rec1_prep <- rec1 %>%
prep() %>%
recipes::bake(new_data = NULL)
```

## 5.2 Define Recipe - rec2 - word embedding

Due to the long calculation time and the relatively poor roc_auc values (with the training resample - v = 2, repeats = 1) , I decided not to perform the calculation for the analysis.

```{r}
#rec2 <-
#recipe(c1 ~ ., data = select(d_train, text, c1, id)) %>%
#update_role(id, new_role = "id") %>%
#step_tokenize(text) %>%
#step_stopwords(text, language = "de", stopword_source = "snowball") %>%
#step_word_embeddings(text, embeddings = word_embedding_text)
```

## 5.3 Define Recipe - rec3 - Word Embeddings

### Insert The Helperfunctions

We are using the package [pradadata](https://github.com/sebastiansauer/pradadata) by @sebastian_sauer_2018_1996614. The data are licensed according to General Public License 3 (GLP-3).

```{r}
data("schimpwoerter", package = "pradadata")
data("sentiws", package = "pradadata")
data("wild_emojis", package = "pradadata")
source("C:/Users/sapi-/OneDrive/Studium/5. Semester/Data Science II/Data_Science_Blog/helper/helper_funs.R")
```

### Insert The Predefined Word Embedding List

The used word embeddings are from @grave2018learning. The data are licensed according to Attribution-ShareAlike 3.0 Unported (CC-BY-SA 3.0).

```{r}
out_file_model <- "C:/Users/sapi-/OneDrive - Hochschule fÃ¼r Angewandte Wissenschaften Ansbach/Desktop/AWM/angewandte Wirtschats- und Medienpsychologie/5. Semester/Word_Embedding/de.300.bin"
```

```{r}
file.exists(out_file_model)
```

```{r}
fasttext_model <- load_model(out_file_model)
dictionary <- get_dictionary(fasttext_model)
get_word_vectors(fasttext_model, c("menschen")) %>% `[`(1:10)
```

```{r}
print(head(dictionary, 10))
```

```{r}
word_embedding_text <- tibble(word = dictionary)
```

```{r}
options(mc.cores = parallel::detectCores())
words_vecs <- get_word_vectors(fasttext_model)
```

```{r output=FALSE}
word_embedding_text <-
word_embedding_text %>%
bind_cols(words_vecs)
```

```{r output=FALSE}
names(word_embedding_text) <- c("word", paste0("v", sprintf("%03d", 1:301)))
```

### rec3

```{r}
rec3 <-
recipe(c1 ~., data = select(d_train, text, c1, id)) %>%
update_role(id, new_role = "id") %>%
step_text_normalization(text) %>%
step_mutate(emo_count = map_int(text, ~count_lexicon(.x, sentiws$word))) %>%
step_mutate(schimpf_count = map_int(text, ~count_lexicon(.x, schimpfwoerter$word))) %>%
step_mutate(wild_emojis = map_int(text, ~count_lexicon(.x, wild_emojis$emoji))) %>%
step_mutate(text_copy = text) %>%
step_textfeature(text_copy) %>%
step_tokenize(text) %>%
step_stopwords(text, language = "de", stopword_source = "snowball") %>%
step_stem(text) %>%
step_word_embeddings(text, embeddings = word_embedding_text)
```

### Prep & Bake - rec3

```{r}
rec3_prep <- rec3 %>%
prep() %>%
recipes::bake(new_data = NULL)
```

## 5.4 Define Recipe - rec4 - TF-IDF

### rec4

```{r}
rec4 <-
recipe(c1 ~., data = select(d_train, text, c1, id)) %>%
update_role(id, new_role = "id") %>% 
step_text_normalization(text) %>%
step_mutate(emo_count = map_int(text, ~count_lexicon(.x, sentiws$word))) %>%
step_mutate(schimpf_count = map_int(text, ~count_lexicon(.x, schimpfwoerter$word))) %>%
step_mutate(wild_emojis = map_int(text, ~count_lexicon(.x, wild_emojis$emoji))) %>%
step_mutate(text_copy = text) %>%
step_textfeature(text_copy) %>%
step_tokenize(text) %>%
step_stopwords(text, language = "de", stopword_source = "snowball") %>%
step_stem(text) %>%
step_tfidf(text)
```

### Prep & Bake - rec4

```{r}
rec4_prep <- rec4 %>%
prep() %>%
recipes::bake(new_data = NULL)
```

# 6. Build Resamples

I chose the v-fold-cross-validation as it is rather time-efficient. Other resampling methods are for example bootstrapping, leave-one-out-cross-validation or hold-out-cross-validation.

For the training I have used v = 2 and repeats = 1. The advantage is, you can train the dataset without such a long calculation time.

```{r}
folds <- vfold_cv(data = d_train,
v = 3,
repeats = 2,
strata = c1)
```

# 7. Build the Penalty-Grid

```{r}
lambda_grid <- grid_regular(penalty(), levels = 25)
```

# 8. Build the Models

## 8.1 Null Model

## 8.2 Lasso-L1 With TF-IDF

According to the large amount of data, I decided to not run the `Null Model` and the `L1-TF-IDF with rec1`.

## 8.3 Ridge-Regression-L2 With TF-IDF

### L2-Model

```{r}
l2_83_mod <- logistic_reg(penalty = tune(), mixture = 0) %>%
set_engine("glmnet") %>%
set_mode("classification")
l2_83_mod
```

### Define The Workflow

```{r}
l2_83_wf <-workflow() %>%
add_recipe(rec1) %>%
add_model(l2_83_mod)
l2_83_wf
```

### Resampling & Model Quality

```{r}
options(mc.cores = parallel::detectCores())
l2_83_wf_fit <- tune_grid(
l2_83_wf,
folds,
grid = lambda_grid,
control = control_resamples(save_pred = TRUE)
)
```

### Model Performance

```{r}
l2_83_wf_fit_performance <- collect_metrics(l2_83_wf_fit)
l2_83_wf_fit_performance
```

```{r}
l2_83_wf_fit_preds <- collect_predictions(l2_83_wf_fit)
```

```{r}
l2_83_wf_fit_preds %>% 
  group_by(id) %>% 
  roc_curve(truth = c1, .pred_OFFENSE) %>% 
  autoplot()
```

### Select The Best

```{r}
chosen_auc_l2_83_wf_fit <-
l2_83_wf_fit %>%
select_by_one_std_err(metric = "roc_auc", -penalty)
chosen_auc_l2_83_wf_fit
```

### Positive Predictive Value

```{r}
ppv(l2_83_wf_fit_preds, truth = factor(c1), estimate = .pred_class)
```

## 8.4 Lasso-L1 With Word Embeddings

Like the `Null Model` (8.1) and the `L1 with TF-IDF` (8.2) I decided to kick the `L1 with Word Embeddings` out of the analysis, because the results in the training phase were too poor, to use it in the prediction phase.

## 8.5 Ridge-Regression-L2 with TF-IDF

### L2-Model

```{r}
l2_85_mod <- logistic_reg(penalty = tune(), mixture = 0) %>%
set_engine("glmnet") %>%
set_mode("classification")
l2_85_mod
```

### Define The Workflow

```{r}
l2_85_wf <-workflow() %>%
add_recipe(rec3) %>%
add_model(l2_85_mod)
l2_85_wf
```

### Resampling & Model Quality

```{r}
options(mc.cores = parallel::detectCores())
l2_85_wf_fit <- tune_grid(
l2_85_wf,
folds,
grid = lambda_grid,
control = control_resamples(save_pred = TRUE)
)
```

### Model Performance

```{r}
l2_85_wf_performance <- collect_metrics(l2_85_wf_fit)
l2_85_wf_performance
```

```{r}
l2_85_wf_fit_preds <- collect_predictions(l2_85_wf_fit)
```

```{r}
l2_85_wf_fit_preds %>% 
  group_by(id) %>% 
  roc_curve(truth = c1, .pred_OFFENSE) %>% 
  autoplot()
```

### Select The Best

```{r}
chosen_auc_l2_85_wf_fit <-
l2_85_wf_fit %>%
select_by_one_std_err(metric = "roc_auc", -penalty)
chosen_auc_l2_85_wf_fit
```

```{r}
conf_mat_resampled(l2_85_wf_fit, tidy = FALSE, parameter = select_best(l2_85_wf_fit)) %>% 
  autoplot(type = "heatmap") 
```

### Positive Predictive Value

```{r}
ppv(l2_85_wf_fit_preds, truth = factor(c1), estimate = .pred_class)
```

## 8.6 Lasso-L1 With TF-IDF

### L1-Model

```{r}
l1_86_mod <- logistic_reg(penalty = tune(), mixture = 1) %>%
set_engine("glmnet") %>%
set_mode("classification")
l1_86_mod
```

### Define The Workflow

```{r}
l1_86_wf <-workflow() %>%
add_recipe(rec4) %>%
add_model(l1_86_mod)
l1_86_wf
```

### Resampling & Model Quality

```{r}
options(mc.cores = parallel::detectCores())
tic()
l1_86_wf_fit <- tune_grid(
l1_86_wf,
folds,
grid = lambda_grid,
control = control_resamples(save_pred = TRUE)
)
toc()
```

### Model Performance

```{r}
l1_86_wf_performance <- collect_metrics(l1_86_wf_fit)
l1_86_wf_performance
```

```{r}
l1_86_wf_fit_preds <- collect_predictions(l1_86_wf_fit)
```

```{r}
l1_86_wf_fit_preds %>% 
  group_by(id) %>% 
  roc_curve(truth = c1, .pred_OFFENSE) %>% 
  autoplot()
```

```{r}
conf_mat_resampled(l1_86_wf_fit, tidy = FALSE, parameter = select_best(l1_86_wf_fit)) %>% 
  autoplot(type = "heatmap") 
```

### Select The Best

```{r}
chosen_auc_l1_86_wf_fit <-
l1_86_wf_fit %>%
select_by_one_std_err(metric = "roc_auc", -penalty)
chosen_auc_l1_86_wf_fit
```

### Positive Predictive Value

```{r}
ppv(l1_86_wf_fit_preds, truth = factor(c1), estimate = .pred_class)
```

## 8.7 Ridge-Regression-L2 With TF-IDF

### L2-Model

```{r}
l2_87_mod <- logistic_reg(penalty = tune(), mixture = 0) %>%
set_engine("glmnet") %>%
set_mode("classification")
l2_87_mod
```

### Define The Workflow

```{r}
l2_87_wf <-workflow() %>%
add_recipe(rec4) %>%
add_model(l2_87_mod)
l2_87_wf
```

### Resampling & Model Quality

```{r}
options(mc.cores = parallel::detectCores())
l2_87_wf_fit <- tune_grid(
l2_87_wf,
folds,
grid = lambda_grid,
control = control_resamples(save_pred = TRUE)
)
```

### Model Performance

```{r}
l2_87_wf_performance <- collect_metrics(l2_87_wf_fit)
l2_87_wf_performance
```

```{r}
l2_87_wf_fit_preds <- collect_predictions(l2_87_wf_fit)
```

```{r}
l2_87_wf_fit_preds %>% 
  group_by(id) %>% 
  roc_curve(truth = c1, .pred_OFFENSE) %>% 
  autoplot()
```

### Select The Best

```{r}
chosen_auc_l2_87_wf_fit <-
l2_87_wf_fit %>%
select_by_one_std_err(metric = "roc_auc", -penalty)
chosen_auc_l2_87_wf_fit
```

```{r}
conf_mat_resampled(l2_87_wf_fit, tidy = FALSE, parameter = select_best(l2_87_wf_fit)) %>% 
  autoplot(type = "heatmap") 
```

### Positive Predictive Value

```{r}
ppv(l2_87_wf_fit_preds, truth = factor(c1), estimate = .pred_class)
```

# 9. Predictions

You will find them [here](https://world-of-datascience.netlify.app/posts/text-mining_solutions/)! ðŸ˜Š
