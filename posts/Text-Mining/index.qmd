---
title: "Datenauswertung "
author: "Sabrina Michl"
date: "2023-01-25"
categories: [code, analysis]
bibliography: ref.bib
image: image.jpg
---

# 1. Preliminary note

For this analysis we use the dataset from @data/0B5VML_2019 out of the zip archive @data/0B5VML/XIUWJ7_2019. The data are licensed according to Attribution 4.0 International (CC-BY-4.0).

The used wordembeddings are from @grave2018learning. The data are licensed according to Attribution-ShareAlike 3.0 Unported (CC-BY-SA 3.0).

The picture, that is used is from @bildquelle.

# 2. Load the packages

```{r output=FALSE}
library(tidyverse)
library(rio)
library(tidymodels)
library(tidytext)
library(textrecipes)
library(lsa)
library(discrim)
library(naivebayes)
library(tictoc)
library(fastrtext)
library(remoji)
library(tokenizers)
```

# 3. Load dataset and minor changes

## Train dataset

```{r output=FALSE}
d_train <- read_tsv("C:/Users/sapi-/OneDrive/Studium/5. Semester/Data Science II/Data_Science_Blog/daten/germeval2018.training.txt", col_names = FALSE)
```

### Rename columns

```{r}
names(d_train) <- c("text", "c1", "c2")
```

### Add ID column

```{r}
d_train <- d_train %>% 
  mutate(id = row_number()) %>% 
  select(id, everything())
```

## Test dataset

```{r output=FALSE}
d_test <- read_tsv("C:/Users/sapi-/OneDrive/Studium/5. Semester/Data Science II/Data_Science_Blog/daten/germeval2018.test.txt", col_names = FALSE)
```

### Rename columns

```{r}
names(d_test) <- c("text", "c1", "c2")
```

### Add ID column

```{r}
d_test <- d_test %>% 
  mutate(id = row_number()) %>% 
  select(id, everything())
```

# 4. Explore dataset

```{r}
train_toc <- d_train %>% 
  unnest_tokens(output = token, input = text)
train_toc
```

> First we tokenize the dataset d_train.

## Insert stopwords_de

```{r}
data(stopwords_de, package = "lsa")
stopwords_de <- tibble(word = stopwords_de)
stopwords_de <- stopwords_de %>% 
  rename(token = word)
```

> After that we use the stopwords_de to `anti_join` this with train_toc.

```{r}
train_toc2 <- train_toc %>% 
  anti_join(stopwords_de)
```

## Show the important words

```{r}
train_toc2 <- train_toc2 %>% 
  count(token, sort = TRUE) 
```

### Plot

```{r}
train_toc2 %>% 
  slice_head(n=20) %>%  
  ggplot()+
  aes(y=reorder(factor(token), n), x = n, color = token)+
  geom_col(aes(fill = token, alpha = 2.5)) +
  ggtitle("The most used words") +
  ylab("token")+
  xlab("quantity")+
  theme_minimal()+
  theme(legend.position = "none")
```
