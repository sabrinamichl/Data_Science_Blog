[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Sabrina",
    "section": "",
    "text": "Hello, my name is Sabrina Michl and this is my new blog about Data Science.\nCurrently I am studying business and media psychology and my major courses are Data Science (surprise) and New Work.\nWith this blog I want to provide insights from the fascinating world of data science.\nHave fun & do not hesitate to get in touch.\nKind regards, Sabrina üòä"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "The World of Data Science",
    "section": "",
    "text": "Text Mining Solution\n\n\n\n\n\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nJan 31, 2023\n\n\nSabrina Michl\n\n\n\n\n\n\n  \n\n\n\n\nText Mining Analysis\n\n\n\n\n\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nJan 30, 2023\n\n\nSabrina Michl\n\n\n\n\n\n\n  \n\n\n\n\nPost With Code\n\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nJan 24, 2023\n\n\nHarlow Malloc\n\n\n\n\n\n\n  \n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\n\n\nJan 21, 2023\n\n\nTristan O‚ÄôMalley\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code."
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn‚Äôt specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/Text-Mining/index.html",
    "href": "posts/Text-Mining/index.html",
    "title": "Text Mining",
    "section": "",
    "text": "For this analysis we use the dataset from Wiegand (2019a) out of the zip archive Wiegand (2019b). The data are licensed according to Attribution 4.0 International (CC-BY-4.0). The used wordembeddings are from Grave et al. (2018). The data are licensed according to Attribution-ShareAlike 3.0 Unported (CC-BY-SA 3.0). The picture, that is used is from Altmann (n.d.)."
  },
  {
    "objectID": "posts/Text-Mining/index.html#trainingsdatensatz",
    "href": "posts/Text-Mining/index.html#trainingsdatensatz",
    "title": "Datenauswertung",
    "section": "Trainingsdatensatz",
    "text": "Trainingsdatensatz\n\nd_train <- read_tsv(\"C:/Users/sapi-/OneDrive/Studium/5. Semester/Data Science II/Data_Science_Blog/daten/germeval2018.training.txt\", col_names = FALSE)\n\nRows: 5009 Columns: 3\n-- Column specification --------------------------------------------------------\nDelimiter: \"\\t\"\nchr (3): X1, X2, X3\n\ni Use `spec()` to retrieve the full column specification for this data.\ni Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nSpalten umbenennen\n\nnames(d_train) <- c(\"text\", \"c1\", \"c2\")\n\n\n\nID-Spalte einf√ºgen\n\nd_train <- d_train %>% \n  mutate(id = row_number()) %>% \n  select(id, everything())"
  },
  {
    "objectID": "posts/Text-Mining/index.html#testdatensatz",
    "href": "posts/Text-Mining/index.html#testdatensatz",
    "title": "Datenauswertung",
    "section": "Testdatensatz",
    "text": "Testdatensatz\n\nd_test <- read_tsv(\"C:/Users/sapi-/OneDrive/Studium/5. Semester/Data Science II/Data_Science_Blog/daten/germeval2018.test.txt\", col_names = FALSE)\n\n\nSpalten umbenennen\n\nnames(d_test) <- c(\"text\", \"c1\", \"c2\")\n\n\n\nID-Spalte einf√ºgen\n\nd_test <- d_test %>% \n  mutate(id = row_number()) %>% \n  select(id, everything())"
  },
  {
    "objectID": "posts/Text-Mining/index.html#train-dataset",
    "href": "posts/Text-Mining/index.html#train-dataset",
    "title": "Text Mining",
    "section": "3.1 Train Dataset",
    "text": "3.1 Train Dataset\n\nd_train <- read_tsv(\"C:/Users/sapi-/OneDrive/Studium/5. Semester/Data Science II/Data_Science_Blog/daten/germeval2018.training.txt\", col_names = FALSE)\n\n\nRename Columns\n\nnames(d_train) <- c(\"text\", \"c1\", \"c2\")\n\n\n\nAdd ID Column\n\nd_train <- d_train %>%\nmutate(id = row_number()) %>%\nselect(id, everything())"
  },
  {
    "objectID": "posts/Text-Mining/index.html#test-dataset",
    "href": "posts/Text-Mining/index.html#test-dataset",
    "title": "Text Mining",
    "section": "3.2 Test Dataset",
    "text": "3.2 Test Dataset\n\nd_test <- read_tsv(\"C:/Users/sapi-/OneDrive/Studium/5. Semester/Data Science II/Data_Science_Blog/daten/germeval2018.test.txt\", col_names = FALSE)\n\n\nRename Columns\n\nnames(d_test) <- c(\"text\", \"c1\", \"c2\")\n\n\n\nAdd ID Column\n\nd_test <- d_test %>%\nmutate(id = row_number()) %>%\nselect(id, everything())"
  },
  {
    "objectID": "posts/Text-Mining/index.html#insert-stopwords_de",
    "href": "posts/Text-Mining/index.html#insert-stopwords_de",
    "title": "Text Mining",
    "section": "Insert stopwords_de",
    "text": "Insert stopwords_de\n\ndata(stopwords_de, package = \"lsa\")\nstopwords_de <- tibble(word = stopwords_de)\nstopwords_de <- stopwords_de %>% \n  rename(token = word)\n\n\nAfter that we use the stopwords_de to anti_join this with train_toc.\n\n\ntrain_toc2 <- train_toc %>% \n  anti_join(stopwords_de)\n\nJoining, by = \"token\""
  },
  {
    "objectID": "posts/Text-Mining/index.html#show-the-important-words",
    "href": "posts/Text-Mining/index.html#show-the-important-words",
    "title": "Text Mining",
    "section": "Show The Important Words",
    "text": "Show The Important Words\n\ntrain_toc2 <- train_toc2 %>%\ncount(token, sort = TRUE)\n\n\nPlot\n\ntrain_toc2 %>%\nslice_head(n=20) %>%\nggplot()+\naes(y=reorder(factor(token), n), x = n, color = token)+\ngeom_col(aes(fill = token, alpha = 2.5)) +\nggtitle(\"The most used words\") +\nylab(\"token\")+\nxlab(\"quantity\")+\ntheme_minimal()+\ntheme(legend.position = \"none\")\n\n\n\n\n\nWe see that, to most used word is ‚Äúlbr‚Äù. We could inspect the dataset way deeper, e. g. do a manual sentimentanalysis or do a lemmatization or stem the words. But we will have a look to these types in the different machine learning algorithm now."
  },
  {
    "objectID": "posts/Text-Mining/index.html#define-recipe---rec1---tf-idf",
    "href": "posts/Text-Mining/index.html#define-recipe---rec1---tf-idf",
    "title": "Text Mining",
    "section": "5.1 Define Recipe - rec1 - TF-IDF",
    "text": "5.1 Define Recipe - rec1 - TF-IDF\n\nrec1 <-\nrecipe(c1 ~ ., data = select(d_train, text, c1, id)) %>%\nupdate_role(id, new_role = \"id\") %>%\nstep_tokenize(text) %>%\nstep_stopwords(text, language = \"de\", stopword_source = \"snowball\") %>%\nstep_stem(text) %>%\nstep_tfidf(text) %>%\nstep_normalize(all_numeric_predictors())\nrec1\n\nRecipe\n\nInputs:\n\n      role #variables\n        id          1\n   outcome          1\n predictor          1\n\nOperations:\n\nTokenization for text\nStop word removal for text\nStemming for text\nTerm frequency-inverse document frequency with text\nCentering and scaling for all_numeric_predictors()\n\n\n\nPrep & Bake - rec1\n\nrec1_prep <- rec1 %>%\nprep() %>%\nrecipes::bake(new_data = NULL)"
  },
  {
    "objectID": "posts/Text-Mining/index.html#define-recipe---rec2---word-embedding",
    "href": "posts/Text-Mining/index.html#define-recipe---rec2---word-embedding",
    "title": "Text Mining",
    "section": "5.2 Define Recipe - rec2 - word embedding",
    "text": "5.2 Define Recipe - rec2 - word embedding\nAfter fitting all the models I have decided to not fit the easy word embedding recipe (rec2)! The reason for this decision is, because of the analysis run-time! We have a large amount of data and extensive recipes, so when I raise the resamples for the prediction, R Studio quits the session.\n\ntraining: v = 1, folds = 2\nprediction: v = 2, folds = 5\n\n\n#rec2 <-\n#recipe(c1 ~ ., data = select(d_train, text, c1, id)) %>%\n#update_role(id, new_role = \"id\") %>%\n#step_tokenize(text) %>%\n#step_stopwords(text, language = \"de\", stopword_source = \"snowball\") %>%\n#step_word_embeddings(text, embeddings = word_embedding_text)\n\n\nInsert The Predefined List\n\nout_file_model <- \"C:/Users/sapi-/OneDrive - Hochschule f√ºr Angewandte Wissenschaften Ansbach/Desktop/AWM/angewandte Wirtschats- und Medienpsychologie/5. Semester/Word_Embedding/de.300.bin\"\n\n\nfile.exists(out_file_model)\n\n[1] TRUE\n\n\n\nfasttext_model <- load_model(out_file_model)\ndictionary <- get_dictionary(fasttext_model)\nget_word_vectors(fasttext_model, c(\"menschen\")) %>% `[`(1:10)\n\n [1] -0.043737594 -0.033647023 -0.016398411  0.037433818  0.029863771\n [6] -0.008217440  0.002691153 -0.027484305 -0.058012061  0.004103063\n\n\n\nprint(head(dictionary, 10))\n\n [1] \",\"    \".\"    \"</s>\" \"und\"  \"der\"  \":\"    \"die\"  \"\\\"\"   \")\"    \"(\"   \n\n\n\nword_embedding_text <- tibble(word = dictionary)\n\n\noptions(mc.cores = parallel::detectCores())\nwords_vecs <- get_word_vectors(fasttext_model)\n\n\nword_embedding_text <-\nword_embedding_text %>%\nbind_cols(words_vecs)\n\n\nnames(word_embedding_text) <- c(\"word\", paste0(\"v\", sprintf(\"%03d\", 1:301)))\n\nWarning: The `value` argument of `names<-` must have the same length as `x` as of tibble\n3.0.0.\ni `names` must have length 301, not 302."
  },
  {
    "objectID": "posts/Text-Mining/index.html#define-recipe---rec3",
    "href": "posts/Text-Mining/index.html#define-recipe---rec3",
    "title": "Text Mining",
    "section": "5.3 Define recipe - rec3",
    "text": "5.3 Define recipe - rec3\n\nDefine helperfunctions\nNow we are using the predefined list of Dirty, Naughty, Obscene and Otherwise Bad Words Patch (n.d.)\n\nschimpf1 <- import(\"https://raw.githubusercontent.com/LDNOOBW/List-of-Dirty-Naughty-Obscene-and-Otherwise-Bad-Words/master/de\", format = \",\", header = FALSE)"
  },
  {
    "objectID": "posts/Text-Mining/index.html#define-recipe---rec3---word-embeddings",
    "href": "posts/Text-Mining/index.html#define-recipe---rec3---word-embeddings",
    "title": "Text Mining",
    "section": "5.3 Define Recipe - rec3 - Word Embeddings",
    "text": "5.3 Define Recipe - rec3 - Word Embeddings\n\nInsert the Helperfunctions\nWe are using the package [pradadata] (https://github.com/sebastiansauer/pradadata) from Sauer (2018). The data are licensed according to General Public License 3 (GLP-3).\n\ndata(\"schimpwoerter\", package = \"pradadata\")\ndata(\"sentiws\", package = \"pradadata\")\ndata(\"wild_emojis\", package = \"pradadata\")\nsource(\"C:/Users/sapi-/OneDrive/Studium/5. Semester/Data Science II/Data_Science_Blog/helper/helper_funs.R\")\n\n\n\nrec3\n\nrec3 <-\nrecipe(c1 ~., data = select(d_train, text, c1, id)) %>%\nupdate_role(id, new_role = \"id\") %>%\nstep_text_normalization(text) %>%\nstep_mutate(emo_count = map_int(text, ~count_lexicon(.x, sentiws$word))) %>%\nstep_mutate(schimpf_count = map_int(text, ~count_lexicon(.x, schimpfwoerter$word))) %>%\nstep_mutate(wild_emojis = map_int(text, ~count_lexicon(.x, wild_emojis$emoji))) %>%\nstep_mutate(text_copy = text) %>%\nstep_textfeature(text_copy) %>%\nstep_tokenize(text) %>%\nstep_stopwords(text, language = \"de\", stopword_source = \"snowball\") %>%\nstep_stem(text) %>%\nstep_word_embeddings(text, embeddings = word_embedding_text)\n\n\nrec3_prep <- rec3 %>%\nprep() %>%\nrecipes::bake(new_data = NULL)"
  },
  {
    "objectID": "posts/Text-Mining/index.html#define-recipe---rec4---tf-idf",
    "href": "posts/Text-Mining/index.html#define-recipe---rec4---tf-idf",
    "title": "Text Mining",
    "section": "5.4 Define Recipe - rec4 - TF-IDF",
    "text": "5.4 Define Recipe - rec4 - TF-IDF\n\nrec4\n\nrec4 <-\nrecipe(c1 ~., data = select(d_train, text, c1, id)) %>%\nupdate_role(id, new_role = \"id\") %>%\nstep_text_normalization(text) %>%\nstep_mutate(emo_count = map_int(text, ~count_lexicon(.x, sentiws$word))) %>%\nstep_mutate(schimpf_count = map_int(text, ~count_lexicon(.x, schimpfwoerter$word))) %>%\nstep_mutate(wild_emojis = map_int(text, ~count_lexicon(.x, wild_emojis$emoji))) %>%\nstep_mutate(text_copy = text) %>%\nstep_textfeature(text_copy) %>%\nstep_tokenize(text) %>%\nstep_stopwords(text, language = \"de\", stopword_source = \"snowball\") %>%\nstep_stem(text) %>%\nstep_tfidf(text)\n\n\nrec4_prep <- rec4 %>%\nprep() %>%\nrecipes::bake(new_data = NULL)"
  },
  {
    "objectID": "posts/Text-Mining/index.html#null-model",
    "href": "posts/Text-Mining/index.html#null-model",
    "title": "Text Mining",
    "section": "8.1 Null Model",
    "text": "8.1 Null Model\n\ntic()\n\n\nmod0 <- null_model() %>%\nset_engine(\"parsnip\") %>%\nset_mode(\"classification\")\n\n\nDefine The Workflow\n\nwf0 <- workflow() %>%\nadd_recipe(rec1) %>%\nadd_model(mod0)\n\n\n\nResampling & Model Quality\n\noptions(mc.cores = parallel::detectCores())\ntic()\nfit0 <- fit_resamples(\nwf0,\nfolds,\ncontrol =control_resamples(save_pred = TRUE)\n)\n\nWarning: Paket 'stopwords' wurde unter R Version 4.1.3 erstellt\n\ntoc()\n\n183.46 sec elapsed\n\n\n\nperformance0 <- collect_metrics(fit0)\nperformance0\n\n# A tibble: 2 x 6\n  .metric  .estimator  mean     n  std_err .config             \n  <chr>    <chr>      <dbl> <int>    <dbl> <chr>               \n1 accuracy binary     0.663     3 0.000132 Preprocessor1_Model1\n2 roc_auc  binary     0.5       3 0        Preprocessor1_Model1\n\n\n\npreds0 <- collect_predictions(fit0)\npreds0 %>%\ngroup_by(id) %>%\nroc_curve(truth = c1, .pred_OFFENSE) %>%\nautoplot()\n\n\n\n\n\nconf_mat_resampled(fit0, tidy = FALSE) %>%\nautoplot(type = \"heatmap\")"
  },
  {
    "objectID": "posts/Text-Mining/index.html#lasso-l1-with-tf-idf",
    "href": "posts/Text-Mining/index.html#lasso-l1-with-tf-idf",
    "title": "Text Mining",
    "section": "8.2 Lasso-L1 With TF-IDF",
    "text": "8.2 Lasso-L1 With TF-IDF\n\nL1-Model\n\nl1_82_mod <- logistic_reg(penalty = tune(), mixture = 1) %>%\nset_engine(\"glmnet\") %>%\nset_mode(\"classification\")\nl1_82_mod\n\nLogistic Regression Model Specification (classification)\n\nMain Arguments:\n  penalty = tune()\n  mixture = 1\n\nComputational engine: glmnet \n\n\n\n\nDefine The Workflow\n\nl1_82_wf <-workflow() %>%\nadd_recipe(rec1) %>%\nadd_model(l1_82_mod)\nl1_82_wf\n\n== Workflow ====================================================================\nPreprocessor: Recipe\nModel: logistic_reg()\n\n-- Preprocessor ----------------------------------------------------------------\n5 Recipe Steps\n\n* step_tokenize()\n* step_stopwords()\n* step_stem()\n* step_tfidf()\n* step_normalize()\n\n-- Model -----------------------------------------------------------------------\nLogistic Regression Model Specification (classification)\n\nMain Arguments:\n  penalty = tune()\n  mixture = 1\n\nComputational engine: glmnet \n\n\n\n\nResampling & Model Quality\n\noptions(mc.cores = parallel::detectCores())\nl1_82_wf_fit <- tune_grid(\nl1_82_wf,\nfolds,\ngrid = lambda_grid,\ncontrol = control_resamples(save_pred = TRUE)\n)\n\nWarning: Paket 'glmnet' wurde unter R Version 4.1.3 erstellt\n\n\nWarning: Paket 'Matrix' wurde unter R Version 4.1.3 erstellt\n\n\n\n\nModel Performance\n\nl1_82_wf_fit_performance <- collect_metrics(l1_82_wf_fit)\nl1_82_wf_fit_performance\n\n# A tibble: 60 x 7\n    penalty .metric  .estimator  mean     n std_err .config              \n      <dbl> <chr>    <chr>      <dbl> <int>   <dbl> <chr>                \n 1 1   e-10 accuracy binary     0.721     3 0.00368 Preprocessor1_Model01\n 2 1   e-10 roc_auc  binary     0.745     3 0.00667 Preprocessor1_Model01\n 3 2.21e-10 accuracy binary     0.721     3 0.00368 Preprocessor1_Model02\n 4 2.21e-10 roc_auc  binary     0.745     3 0.00667 Preprocessor1_Model02\n 5 4.89e-10 accuracy binary     0.721     3 0.00368 Preprocessor1_Model03\n 6 4.89e-10 roc_auc  binary     0.745     3 0.00667 Preprocessor1_Model03\n 7 1.08e- 9 accuracy binary     0.721     3 0.00368 Preprocessor1_Model04\n 8 1.08e- 9 roc_auc  binary     0.745     3 0.00667 Preprocessor1_Model04\n 9 2.40e- 9 accuracy binary     0.721     3 0.00368 Preprocessor1_Model05\n10 2.40e- 9 roc_auc  binary     0.745     3 0.00667 Preprocessor1_Model05\n# ... with 50 more rows\n\n\n\nl1_82_wf_fit_preds <- collect_predictions(l1_82_wf_fit)\n\n\nl1_82_wf_fit_preds %>% \n  group_by(id) %>% \n  roc_curve(truth = c1, .pred_OFFENSE) %>% \n  autoplot()\n\n\n\n\n\nautoplot(l1_82_wf_fit)\n\n\n\n\n\n\nSelect The Best\n\nchosen_auc_l1_82_wf_fit <-\nl1_82_wf_fit %>%\nselect_by_one_std_err(metric = \"roc_auc\", -penalty)\nchosen_auc_l1_82_wf_fit\n\n# A tibble: 1 x 9\n  penalty .metric .estimator  mean     n std_err .config            .best .bound\n    <dbl> <chr>   <chr>      <dbl> <int>   <dbl> <chr>              <dbl>  <dbl>\n1 0.00853 roc_auc binary     0.758     3 0.00567 Preprocessor1_Mod~ 0.758  0.753"
  },
  {
    "objectID": "posts/Text-Mining/index.html#ridge-regression-l2-with-tf-idf",
    "href": "posts/Text-Mining/index.html#ridge-regression-l2-with-tf-idf",
    "title": "Text Mining",
    "section": "8.3 Ridge-Regression-L2 With TF-IDF",
    "text": "8.3 Ridge-Regression-L2 With TF-IDF\n\nL2-Model\n\nl2_83_mod <- logistic_reg(penalty = tune(), mixture = 0) %>%\nset_engine(\"glmnet\") %>%\nset_mode(\"classification\")\nl2_83_mod\n\nLogistic Regression Model Specification (classification)\n\nMain Arguments:\n  penalty = tune()\n  mixture = 0\n\nComputational engine: glmnet \n\n\n\n\nDefine The Workflow\n\nl2_83_wf <-workflow() %>%\nadd_recipe(rec1) %>%\nadd_model(l2_83_mod)\nl2_83_wf\n\n== Workflow ====================================================================\nPreprocessor: Recipe\nModel: logistic_reg()\n\n-- Preprocessor ----------------------------------------------------------------\n5 Recipe Steps\n\n* step_tokenize()\n* step_stopwords()\n* step_stem()\n* step_tfidf()\n* step_normalize()\n\n-- Model -----------------------------------------------------------------------\nLogistic Regression Model Specification (classification)\n\nMain Arguments:\n  penalty = tune()\n  mixture = 0\n\nComputational engine: glmnet \n\n\n\n\nResampling & Model Quality\n\noptions(mc.cores = parallel::detectCores())\nl2_83_wf_fit <- tune_grid(\nl2_83_wf,\nfolds,\ngrid = lambda_grid,\ncontrol = control_resamples(save_pred = TRUE)\n)\n\n\ncollect_metrics(l2_83_wf_fit)\n\n# A tibble: 60 x 7\n    penalty .metric  .estimator  mean     n std_err .config              \n      <dbl> <chr>    <chr>      <dbl> <int>   <dbl> <chr>                \n 1 1   e-10 accuracy binary     0.709     3 0.00430 Preprocessor1_Model01\n 2 1   e-10 roc_auc  binary     0.753     3 0.00666 Preprocessor1_Model01\n 3 2.21e-10 accuracy binary     0.709     3 0.00430 Preprocessor1_Model02\n 4 2.21e-10 roc_auc  binary     0.753     3 0.00666 Preprocessor1_Model02\n 5 4.89e-10 accuracy binary     0.709     3 0.00430 Preprocessor1_Model03\n 6 4.89e-10 roc_auc  binary     0.753     3 0.00666 Preprocessor1_Model03\n 7 1.08e- 9 accuracy binary     0.709     3 0.00430 Preprocessor1_Model04\n 8 1.08e- 9 roc_auc  binary     0.753     3 0.00666 Preprocessor1_Model04\n 9 2.40e- 9 accuracy binary     0.709     3 0.00430 Preprocessor1_Model05\n10 2.40e- 9 roc_auc  binary     0.753     3 0.00666 Preprocessor1_Model05\n# ... with 50 more rows\n\n\n\n\nModel Performance\n\nl2_83_wf_fit_performance <- collect_metrics(l2_83_wf_fit)\nl2_83_wf_fit_performance\n\n# A tibble: 60 x 7\n    penalty .metric  .estimator  mean     n std_err .config              \n      <dbl> <chr>    <chr>      <dbl> <int>   <dbl> <chr>                \n 1 1   e-10 accuracy binary     0.709     3 0.00430 Preprocessor1_Model01\n 2 1   e-10 roc_auc  binary     0.753     3 0.00666 Preprocessor1_Model01\n 3 2.21e-10 accuracy binary     0.709     3 0.00430 Preprocessor1_Model02\n 4 2.21e-10 roc_auc  binary     0.753     3 0.00666 Preprocessor1_Model02\n 5 4.89e-10 accuracy binary     0.709     3 0.00430 Preprocessor1_Model03\n 6 4.89e-10 roc_auc  binary     0.753     3 0.00666 Preprocessor1_Model03\n 7 1.08e- 9 accuracy binary     0.709     3 0.00430 Preprocessor1_Model04\n 8 1.08e- 9 roc_auc  binary     0.753     3 0.00666 Preprocessor1_Model04\n 9 2.40e- 9 accuracy binary     0.709     3 0.00430 Preprocessor1_Model05\n10 2.40e- 9 roc_auc  binary     0.753     3 0.00666 Preprocessor1_Model05\n# ... with 50 more rows\n\n\n\nl2_83_wf_fit_preds <- collect_predictions(l2_83_wf_fit)\n\n\nl2_83_wf_fit_preds %>% \n  group_by(id) %>% \n  roc_curve(truth = c1, .pred_OFFENSE) %>% \n  autoplot()\n\n\n\n\n\n\nSelect The Best\n\nchosen_auc_l2_83_wf_fit <-\nl2_83_wf_fit %>%\nselect_by_one_std_err(metric = \"roc_auc\", -penalty)\nchosen_auc_l2_83_wf_fit\n\n# A tibble: 1 x 9\n  penalty .metric .estimator  mean     n std_err .config            .best .bound\n    <dbl> <chr>   <chr>      <dbl> <int>   <dbl> <chr>              <dbl>  <dbl>\n1       1 roc_auc binary     0.754     3 0.00643 Preprocessor1_Mod~ 0.754  0.747"
  },
  {
    "objectID": "posts/Text-Mining/index.html#lasso-l1-with-word-embeddings",
    "href": "posts/Text-Mining/index.html#lasso-l1-with-word-embeddings",
    "title": "Text Mining",
    "section": "8.4 Lasso-L1 With Word Embeddings",
    "text": "8.4 Lasso-L1 With Word Embeddings\n\nL1-Model\n\nl1_84_mod <- logistic_reg(penalty = tune(), mixture = 1) %>%\nset_engine(\"glmnet\") %>%\nset_mode(\"classification\")\nl1_84_mod\n\nLogistic Regression Model Specification (classification)\n\nMain Arguments:\n  penalty = tune()\n  mixture = 1\n\nComputational engine: glmnet \n\n\n\n\nDefine The Workflow\n\nl1_84_wf <- workflow() %>%\nadd_recipe(rec3) %>%\nadd_model(l1_84_mod)\nl1_84_wf\n\n== Workflow ====================================================================\nPreprocessor: Recipe\nModel: logistic_reg()\n\n-- Preprocessor ----------------------------------------------------------------\n10 Recipe Steps\n\n* step_text_normalization()\n* step_mutate()\n* step_mutate()\n* step_mutate()\n* step_mutate()\n* step_textfeature()\n* step_tokenize()\n* step_stopwords()\n* step_stem()\n* step_word_embeddings()\n\n-- Model -----------------------------------------------------------------------\nLogistic Regression Model Specification (classification)\n\nMain Arguments:\n  penalty = tune()\n  mixture = 1\n\nComputational engine: glmnet \n\n\n\n\nResampling & Model Quality\n\noptions(mc.cores = parallel::detectCores())\nl1_84_wf_fit <- tune_grid(\nl1_84_wf,\nfolds,\ngrid = lambda_grid,\ncontrol = control_resamples(save_pred = TRUE)\n)\n\nWarning: Paket 'stringi' wurde unter R Version 4.1.2 erstellt\n\n\nWarning: Paket 'textfeatures' wurde unter R Version 4.1.3 erstellt\n\n\n\ncollect_metrics(l1_84_wf_fit)\n\n# A tibble: 60 x 7\n    penalty .metric  .estimator  mean     n std_err .config              \n      <dbl> <chr>    <chr>      <dbl> <int>   <dbl> <chr>                \n 1 1   e-10 accuracy binary     0.728     3 0.00597 Preprocessor1_Model01\n 2 1   e-10 roc_auc  binary     0.752     3 0.00283 Preprocessor1_Model01\n 3 2.21e-10 accuracy binary     0.728     3 0.00597 Preprocessor1_Model02\n 4 2.21e-10 roc_auc  binary     0.752     3 0.00283 Preprocessor1_Model02\n 5 4.89e-10 accuracy binary     0.728     3 0.00597 Preprocessor1_Model03\n 6 4.89e-10 roc_auc  binary     0.752     3 0.00283 Preprocessor1_Model03\n 7 1.08e- 9 accuracy binary     0.728     3 0.00597 Preprocessor1_Model04\n 8 1.08e- 9 roc_auc  binary     0.752     3 0.00283 Preprocessor1_Model04\n 9 2.40e- 9 accuracy binary     0.728     3 0.00597 Preprocessor1_Model05\n10 2.40e- 9 roc_auc  binary     0.752     3 0.00283 Preprocessor1_Model05\n# ... with 50 more rows\n\n\n\n\nModel Performance\n\nl1_84_wf_fit_performance <- collect_metrics(l1_84_wf_fit)\nl1_84_wf_fit_performance\n\n# A tibble: 60 x 7\n    penalty .metric  .estimator  mean     n std_err .config              \n      <dbl> <chr>    <chr>      <dbl> <int>   <dbl> <chr>                \n 1 1   e-10 accuracy binary     0.728     3 0.00597 Preprocessor1_Model01\n 2 1   e-10 roc_auc  binary     0.752     3 0.00283 Preprocessor1_Model01\n 3 2.21e-10 accuracy binary     0.728     3 0.00597 Preprocessor1_Model02\n 4 2.21e-10 roc_auc  binary     0.752     3 0.00283 Preprocessor1_Model02\n 5 4.89e-10 accuracy binary     0.728     3 0.00597 Preprocessor1_Model03\n 6 4.89e-10 roc_auc  binary     0.752     3 0.00283 Preprocessor1_Model03\n 7 1.08e- 9 accuracy binary     0.728     3 0.00597 Preprocessor1_Model04\n 8 1.08e- 9 roc_auc  binary     0.752     3 0.00283 Preprocessor1_Model04\n 9 2.40e- 9 accuracy binary     0.728     3 0.00597 Preprocessor1_Model05\n10 2.40e- 9 roc_auc  binary     0.752     3 0.00283 Preprocessor1_Model05\n# ... with 50 more rows\n\n\n\nl1_84_wf_fit_preds <- collect_predictions(l1_84_wf_fit)\n\n\nl1_84_wf_fit_preds %>% \n  group_by(id) %>% \n  roc_curve(truth = c1, .pred_OFFENSE) %>% \n  autoplot()\n\n\n\n\n\n\nSelect The Best\n\nchosen_auc_l1_84_wf_fit <-\nl1_84_wf_fit %>%\nselect_by_one_std_err(metric = \"roc_auc\", -penalty)\nchosen_auc_l1_84_wf_fit\n\n# A tibble: 1 x 9\n  penalty .metric .estimator  mean     n std_err .config            .best .bound\n    <dbl> <chr>   <chr>      <dbl> <int>   <dbl> <chr>              <dbl>  <dbl>\n1 0.00386 roc_auc binary     0.768     3 0.00581 Preprocessor1_Mod~ 0.768  0.762"
  },
  {
    "objectID": "posts/Text-Mining/index.html#ridge-regression-l2-with-word-embeddings",
    "href": "posts/Text-Mining/index.html#ridge-regression-l2-with-word-embeddings",
    "title": "Text Mining",
    "section": "8.5 Ridge-Regression-L2 With Word Embeddings",
    "text": "8.5 Ridge-Regression-L2 With Word Embeddings\n\nL2-Model\n\nl2_8.5_mod <- logistic_reg(penalty = tune(), mixture = 0) %>%\nset_engine(\"glmnet\") %>%\nset_mode(\"classification\")\nl2_8.5_mod\n\nLogistic Regression Model Specification (classification)\n\nMain Arguments:\n  penalty = tune()\n  mixture = 0\n\nComputational engine: glmnet \n\n\n\n\nDefine the Workflow\n\nl2_8.5_wf <- workflow() %>%\nadd_recipe(rec2) %>%\nadd_model(l2_8.5_mod)\nl2_8.5_wf\n\n== Workflow ====================================================================\nPreprocessor: Recipe\nModel: logistic_reg()\n\n-- Preprocessor ----------------------------------------------------------------\n3 Recipe Steps\n\n* step_tokenize()\n* step_stopwords()\n* step_word_embeddings()\n\n-- Model -----------------------------------------------------------------------\nLogistic Regression Model Specification (classification)\n\nMain Arguments:\n  penalty = tune()\n  mixture = 0\n\nComputational engine: glmnet \n\n\n\n\nResampling & Model Quality\n\noptions(mc.cores = parallel::detectCores())\nl2_8.5_wf_fit <- tune_grid(\nl2_8.5_wf,\nfolds,\ngrid = lambda_grid,\ncontrol = control_resamples(save_pred = TRUE)\n)\n\n\ncollect_metrics(l2_8.5_wf_fit)\n\n# A tibble: 60 x 7\n    penalty .metric  .estimator  mean     n std_err .config              \n      <dbl> <chr>    <chr>      <dbl> <int>   <dbl> <chr>                \n 1 1   e-10 accuracy binary     0.702     2 0.00753 Preprocessor1_Model01\n 2 1   e-10 roc_auc  binary     0.703     2 0.00244 Preprocessor1_Model01\n 3 2.21e-10 accuracy binary     0.702     2 0.00753 Preprocessor1_Model02\n 4 2.21e-10 roc_auc  binary     0.703     2 0.00244 Preprocessor1_Model02\n 5 4.89e-10 accuracy binary     0.702     2 0.00753 Preprocessor1_Model03\n 6 4.89e-10 roc_auc  binary     0.703     2 0.00244 Preprocessor1_Model03\n 7 1.08e- 9 accuracy binary     0.702     2 0.00753 Preprocessor1_Model04\n 8 1.08e- 9 roc_auc  binary     0.703     2 0.00244 Preprocessor1_Model04\n 9 2.40e- 9 accuracy binary     0.702     2 0.00753 Preprocessor1_Model05\n10 2.40e- 9 roc_auc  binary     0.703     2 0.00244 Preprocessor1_Model05\n# ... with 50 more rows\n\n\n\n\nSelect The Best\n\nchosen_auc_l2_8.5_wf_fit <-\nl2_8.5_wf_fit %>%\nselect_by_one_std_err(metric = \"roc_auc\", -penalty)\nchosen_auc_l2_8.5_wf_fit\n\n# A tibble: 1 x 9\n  penalty .metric .estimator  mean     n  std_err .config           .best .bound\n    <dbl> <chr>   <chr>      <dbl> <int>    <dbl> <chr>             <dbl>  <dbl>\n1   0.204 roc_auc binary     0.717     2 0.000538 Preprocessor1_Mo~ 0.717  0.717"
  },
  {
    "objectID": "posts/Text-Mining/index.html#lasso-l1-with-word-embeddings-1",
    "href": "posts/Text-Mining/index.html#lasso-l1-with-word-embeddings-1",
    "title": "Text Mining",
    "section": "8.6 Lasso-L1 With Word Embeddings",
    "text": "8.6 Lasso-L1 With Word Embeddings\n\nL1-Model\n\nl1_8.6_mod <- logistic_reg(penalty = tune(), mixture = 1) %>%\nset_engine(\"glmnet\") %>%\nset_mode(\"classification\")\nl1_8.6_mod\n\nLogistic Regression Model Specification (classification)\n\nMain Arguments:\n  penalty = tune()\n  mixture = 1\n\nComputational engine: glmnet \n\n\n\n\nDefine The Workflow\n\nl1_8.6_wf <- workflow() %>%\nadd_recipe(rec3) %>%\nadd_model(l1_8.6_mod)\nl1_8.6_wf\n\n== Workflow ====================================================================\nPreprocessor: Recipe\nModel: logistic_reg()\n\n-- Preprocessor ----------------------------------------------------------------\n10 Recipe Steps\n\n* step_text_normalization()\n* step_mutate()\n* step_mutate()\n* step_mutate()\n* step_mutate()\n* step_textfeature()\n* step_tokenize()\n* step_stopwords()\n* step_stem()\n* step_word_embeddings()\n\n-- Model -----------------------------------------------------------------------\nLogistic Regression Model Specification (classification)\n\nMain Arguments:\n  penalty = tune()\n  mixture = 1\n\nComputational engine: glmnet \n\n\n\n\nResampling & Model Quality\n\noptions(mc.cores = parallel::detectCores())\nl1_8.6_wf_fit <- tune_grid(\nl1_8.6_wf,\nfolds,\ngrid = lambda_grid,\ncontrol = control_resamples(save_pred = TRUE)\n)\n\nWarning: Paket 'stringi' wurde unter R Version 4.1.2 erstellt\n\n\nWarning: Paket 'textfeatures' wurde unter R Version 4.1.3 erstellt\n\n\n\ncollect_metrics(l1_8.6_wf_fit)\n\n# A tibble: 60 x 7\n    penalty .metric  .estimator  mean     n   std_err .config              \n      <dbl> <chr>    <chr>      <dbl> <int>     <dbl> <chr>                \n 1 1   e-10 accuracy binary     0.718     2 0.000855  Preprocessor1_Model01\n 2 1   e-10 roc_auc  binary     0.728     2 0.0000880 Preprocessor1_Model01\n 3 2.21e-10 accuracy binary     0.718     2 0.000855  Preprocessor1_Model02\n 4 2.21e-10 roc_auc  binary     0.728     2 0.0000880 Preprocessor1_Model02\n 5 4.89e-10 accuracy binary     0.718     2 0.000855  Preprocessor1_Model03\n 6 4.89e-10 roc_auc  binary     0.728     2 0.0000880 Preprocessor1_Model03\n 7 1.08e- 9 accuracy binary     0.718     2 0.000855  Preprocessor1_Model04\n 8 1.08e- 9 roc_auc  binary     0.728     2 0.0000880 Preprocessor1_Model04\n 9 2.40e- 9 accuracy binary     0.718     2 0.000855  Preprocessor1_Model05\n10 2.40e- 9 roc_auc  binary     0.728     2 0.0000880 Preprocessor1_Model05\n# ... with 50 more rows\n\n\n\n\nSelect The Best\n\nchosen_auc_l1_8.6_wf_fit <-\nl1_8.6_wf_fit %>%\nselect_by_one_std_err(metric = \"roc_auc\", -penalty)\nchosen_auc_l1_8.6_wf_fit\n\n# A tibble: 1 x 9\n  penalty .metric .estimator  mean     n std_err .config            .best .bound\n    <dbl> <chr>   <chr>      <dbl> <int>   <dbl> <chr>              <dbl>  <dbl>\n1 0.00853 roc_auc binary     0.743     2 0.00519 Preprocessor1_Mod~ 0.746  0.743"
  },
  {
    "objectID": "posts/Text-Mining/index.html#ridge-regression-l2-with-tf-idf-1",
    "href": "posts/Text-Mining/index.html#ridge-regression-l2-with-tf-idf-1",
    "title": "Text Mining",
    "section": "8.5 Ridge-Regression-L2 with TF-IDF",
    "text": "8.5 Ridge-Regression-L2 with TF-IDF\n\nL2-Model\n\nl2_85_mod <- logistic_reg(penalty = tune(), mixture = 0) %>%\nset_engine(\"glmnet\") %>%\nset_mode(\"classification\")\nl2_85_mod\n\nLogistic Regression Model Specification (classification)\n\nMain Arguments:\n  penalty = tune()\n  mixture = 0\n\nComputational engine: glmnet \n\n\n\n\nDefine The Workflow\n\nl2_85_wf <-workflow() %>%\nadd_recipe(rec3) %>%\nadd_model(l2_85_mod)\nl2_85_wf\n\n== Workflow ====================================================================\nPreprocessor: Recipe\nModel: logistic_reg()\n\n-- Preprocessor ----------------------------------------------------------------\n10 Recipe Steps\n\n* step_text_normalization()\n* step_mutate()\n* step_mutate()\n* step_mutate()\n* step_mutate()\n* step_textfeature()\n* step_tokenize()\n* step_stopwords()\n* step_stem()\n* step_word_embeddings()\n\n-- Model -----------------------------------------------------------------------\nLogistic Regression Model Specification (classification)\n\nMain Arguments:\n  penalty = tune()\n  mixture = 0\n\nComputational engine: glmnet \n\n\n\n\nResampling & Model Quality\n\noptions(mc.cores = parallel::detectCores())\nl2_85_wf_fit <- tune_grid(\nl2_85_wf,\nfolds,\ngrid = lambda_grid,\ncontrol = control_resamples(save_pred = TRUE)\n)\n\n\n\nModel Performance\n\nl2_85_wf_performance <- collect_metrics(l2_85_wf_fit)\nl2_85_wf_performance\n\n# A tibble: 60 x 7\n    penalty .metric  .estimator  mean     n std_err .config              \n      <dbl> <chr>    <chr>      <dbl> <int>   <dbl> <chr>                \n 1 1   e-10 accuracy binary     0.738     3 0.00463 Preprocessor1_Model01\n 2 1   e-10 roc_auc  binary     0.764     3 0.00495 Preprocessor1_Model01\n 3 2.21e-10 accuracy binary     0.738     3 0.00463 Preprocessor1_Model02\n 4 2.21e-10 roc_auc  binary     0.764     3 0.00495 Preprocessor1_Model02\n 5 4.89e-10 accuracy binary     0.738     3 0.00463 Preprocessor1_Model03\n 6 4.89e-10 roc_auc  binary     0.764     3 0.00495 Preprocessor1_Model03\n 7 1.08e- 9 accuracy binary     0.738     3 0.00463 Preprocessor1_Model04\n 8 1.08e- 9 roc_auc  binary     0.764     3 0.00495 Preprocessor1_Model04\n 9 2.40e- 9 accuracy binary     0.738     3 0.00463 Preprocessor1_Model05\n10 2.40e- 9 roc_auc  binary     0.764     3 0.00495 Preprocessor1_Model05\n# ... with 50 more rows\n\n\n\nl2_85_wf_fit_preds <- collect_predictions(l2_85_wf_fit)\n\n\nl2_85_wf_fit_preds %>% \n  group_by(id) %>% \n  roc_curve(truth = c1, .pred_OFFENSE) %>% \n  autoplot()\n\n\n\n\n\n\nShow The Best\n\nshow_best(l2_85_wf_fit)\n\nWarning: No value of `metric` was given; metric 'roc_auc' will be used.\n\n\n# A tibble: 5 x 7\n       penalty .metric .estimator  mean     n std_err .config              \n         <dbl> <chr>   <chr>      <dbl> <int>   <dbl> <chr>                \n1 0.0924       roc_auc binary     0.769     3 0.00616 Preprocessor1_Model27\n2 0.0418       roc_auc binary     0.769     3 0.00609 Preprocessor1_Model26\n3 0.204        roc_auc binary     0.767     3 0.00633 Preprocessor1_Model28\n4 0.0189       roc_auc binary     0.767     3 0.00543 Preprocessor1_Model25\n5 0.0000000001 roc_auc binary     0.764     3 0.00495 Preprocessor1_Model01\n\n\n\n\nSelect The Best\n\nchosen_auc_l2_85_wf_fit <-\nl2_85_wf_fit %>%\nselect_by_one_std_err(metric = \"roc_auc\", -penalty)\nchosen_auc_l2_85_wf_fit\n\n# A tibble: 1 x 9\n  penalty .metric .estimator  mean     n std_err .config            .best .bound\n    <dbl> <chr>   <chr>      <dbl> <int>   <dbl> <chr>              <dbl>  <dbl>\n1   0.204 roc_auc binary     0.767     3 0.00633 Preprocessor1_Mod~ 0.769  0.763"
  },
  {
    "objectID": "posts/Text-Mining/index.html#lasso-l1-with-tf-idf-1",
    "href": "posts/Text-Mining/index.html#lasso-l1-with-tf-idf-1",
    "title": "Text Mining",
    "section": "8.6 Lasso-L1 With TF-IDF",
    "text": "8.6 Lasso-L1 With TF-IDF\n\nL1-Model\n\nl1_86_mod <- logistic_reg(penalty = tune(), mixture = 1) %>%\nset_engine(\"glmnet\") %>%\nset_mode(\"classification\")\nl1_86_mod\n\nLogistic Regression Model Specification (classification)\n\nMain Arguments:\n  penalty = tune()\n  mixture = 1\n\nComputational engine: glmnet \n\n\n\n\nDefine The Workflow\n\nl1_86_wf <-workflow() %>%\nadd_recipe(rec4) %>%\nadd_model(l1_86_mod)\nl1_86_wf\n\n== Workflow ====================================================================\nPreprocessor: Recipe\nModel: logistic_reg()\n\n-- Preprocessor ----------------------------------------------------------------\n10 Recipe Steps\n\n* step_text_normalization()\n* step_mutate()\n* step_mutate()\n* step_mutate()\n* step_mutate()\n* step_textfeature()\n* step_tokenize()\n* step_stopwords()\n* step_stem()\n* step_tfidf()\n\n-- Model -----------------------------------------------------------------------\nLogistic Regression Model Specification (classification)\n\nMain Arguments:\n  penalty = tune()\n  mixture = 1\n\nComputational engine: glmnet \n\n\n\n\nResampling & Model Quality\n\noptions(mc.cores = parallel::detectCores())\nl1_86_wf_fit <- tune_grid(\nl1_86_wf,\nfolds,\ngrid = lambda_grid,\ncontrol = control_resamples(save_pred = TRUE)\n)\n\n\n\nModel Performance\n\nl1_86_wf_performance <- collect_metrics(l1_86_wf_fit)\nl1_86_wf_performance\n\n# A tibble: 60 x 7\n    penalty .metric  .estimator  mean     n std_err .config              \n      <dbl> <chr>    <chr>      <dbl> <int>   <dbl> <chr>                \n 1 1   e-10 accuracy binary     0.743     3 0.00515 Preprocessor1_Model01\n 2 1   e-10 roc_auc  binary     0.771     3 0.00695 Preprocessor1_Model01\n 3 2.21e-10 accuracy binary     0.743     3 0.00515 Preprocessor1_Model02\n 4 2.21e-10 roc_auc  binary     0.771     3 0.00695 Preprocessor1_Model02\n 5 4.89e-10 accuracy binary     0.743     3 0.00515 Preprocessor1_Model03\n 6 4.89e-10 roc_auc  binary     0.771     3 0.00695 Preprocessor1_Model03\n 7 1.08e- 9 accuracy binary     0.743     3 0.00515 Preprocessor1_Model04\n 8 1.08e- 9 roc_auc  binary     0.771     3 0.00695 Preprocessor1_Model04\n 9 2.40e- 9 accuracy binary     0.743     3 0.00515 Preprocessor1_Model05\n10 2.40e- 9 roc_auc  binary     0.771     3 0.00695 Preprocessor1_Model05\n# ... with 50 more rows\n\n\n\nl1_86_wf_fit_preds <- collect_predictions(l1_86_wf_fit)\n\n\nl1_86_wf_fit_preds %>% \n  group_by(id) %>% \n  roc_curve(truth = c1, .pred_OFFENSE) %>% \n  autoplot()\n\n\n\n\n\n\nShow The Best\n\nselect_best(l1_86_wf_fit)\n\nWarning: No value of `metric` was given; metric 'roc_auc' will be used.\n\n\n# A tibble: 1 x 2\n  penalty .config              \n    <dbl> <chr>                \n1 0.00853 Preprocessor1_Model24\n\n\n\n\nSelect The Best\n\nchosen_auc_l1_86_wf_fit <-\nl1_86_wf_fit %>%\nselect_by_one_std_err(metric = \"roc_auc\", -penalty)\nchosen_auc_l1_86_wf_fit\n\n# A tibble: 1 x 9\n  penalty .metric .estimator  mean     n std_err .config            .best .bound\n    <dbl> <chr>   <chr>      <dbl> <int>   <dbl> <chr>              <dbl>  <dbl>\n1 0.00853 roc_auc binary     0.781     3 0.00762 Preprocessor1_Mod~ 0.781  0.773"
  },
  {
    "objectID": "posts/Text-Mining/index.html#ridge-regression-l2-with-tf-idf-2",
    "href": "posts/Text-Mining/index.html#ridge-regression-l2-with-tf-idf-2",
    "title": "Text Mining",
    "section": "8.7 Ridge-Regression-L2 With TF-IDF",
    "text": "8.7 Ridge-Regression-L2 With TF-IDF\n\nL2-Model\n\nl2_87_mod <- logistic_reg(penalty = tune(), mixture = 0) %>%\nset_engine(\"glmnet\") %>%\nset_mode(\"classification\")\nl2_87_mod\n\nLogistic Regression Model Specification (classification)\n\nMain Arguments:\n  penalty = tune()\n  mixture = 0\n\nComputational engine: glmnet \n\n\n\n\nDefine The Workflow\n\nl2_87_wf <-workflow() %>%\nadd_recipe(rec4) %>%\nadd_model(l2_87_mod)\nl2_87_wf\n\n== Workflow ====================================================================\nPreprocessor: Recipe\nModel: logistic_reg()\n\n-- Preprocessor ----------------------------------------------------------------\n10 Recipe Steps\n\n* step_text_normalization()\n* step_mutate()\n* step_mutate()\n* step_mutate()\n* step_mutate()\n* step_textfeature()\n* step_tokenize()\n* step_stopwords()\n* step_stem()\n* step_tfidf()\n\n-- Model -----------------------------------------------------------------------\nLogistic Regression Model Specification (classification)\n\nMain Arguments:\n  penalty = tune()\n  mixture = 0\n\nComputational engine: glmnet \n\n\n\n\nResampling & Model Quality\n\noptions(mc.cores = parallel::detectCores())\nl2_87_wf_fit <- tune_grid(\nl2_87_wf,\nfolds,\ngrid = lambda_grid,\ncontrol = control_resamples(save_pred = TRUE)\n)\n\n\n\nModel Performance\n\nl2_87_wf_performance <- collect_metrics(l2_87_wf_fit)\nl2_87_wf_performance\n\n# A tibble: 60 x 7\n    penalty .metric  .estimator  mean     n std_err .config              \n      <dbl> <chr>    <chr>      <dbl> <int>   <dbl> <chr>                \n 1 1   e-10 accuracy binary     0.707     3 0.00306 Preprocessor1_Model01\n 2 1   e-10 roc_auc  binary     0.765     3 0.00667 Preprocessor1_Model01\n 3 2.21e-10 accuracy binary     0.707     3 0.00306 Preprocessor1_Model02\n 4 2.21e-10 roc_auc  binary     0.765     3 0.00667 Preprocessor1_Model02\n 5 4.89e-10 accuracy binary     0.707     3 0.00306 Preprocessor1_Model03\n 6 4.89e-10 roc_auc  binary     0.765     3 0.00667 Preprocessor1_Model03\n 7 1.08e- 9 accuracy binary     0.707     3 0.00306 Preprocessor1_Model04\n 8 1.08e- 9 roc_auc  binary     0.765     3 0.00667 Preprocessor1_Model04\n 9 2.40e- 9 accuracy binary     0.707     3 0.00306 Preprocessor1_Model05\n10 2.40e- 9 roc_auc  binary     0.765     3 0.00667 Preprocessor1_Model05\n# ... with 50 more rows\n\n\n\nl2_87_wf_fit_preds <- collect_predictions(l2_87_wf_fit)\n\n\nl2_87_wf_fit_preds %>% \n  group_by(id) %>% \n  roc_curve(truth = c1, .pred_OFFENSE) %>% \n  autoplot()\n\n\n\n\n\n\nSelect The Best\n\nchosen_auc_l2_87_wf_fit <-\nl2_87_wf_fit %>%\nselect_by_one_std_err(metric = \"roc_auc\", -penalty)\nchosen_auc_l2_87_wf_fit\n\n# A tibble: 1 x 9\n  penalty .metric .estimator  mean     n std_err .config            .best .bound\n    <dbl> <chr>   <chr>      <dbl> <int>   <dbl> <chr>              <dbl>  <dbl>\n1       1 roc_auc binary     0.765     3 0.00667 Preprocessor1_Mod~ 0.765  0.758\n\n\n\ntoc()\n\n2836.8 sec elapsed"
  },
  {
    "objectID": "posts/Text-Mining_NEW/index.html",
    "href": "posts/Text-Mining_NEW/index.html",
    "title": "Text Mining Analysis",
    "section": "",
    "text": "For this analysis we use the dataset from Wiegand (2019a) out of the zip archive Wiegand (2019b). The data are licensed according to Attribution 4.0 International (CC-BY-4.0).\nThe picture to this post from the welcome page, is from Gerd Altmann at Pixabay"
  },
  {
    "objectID": "posts/Text-Mining_NEW/index.html#train-dataset",
    "href": "posts/Text-Mining_NEW/index.html#train-dataset",
    "title": "Text Mining Analysis",
    "section": "3.1 Train Dataset",
    "text": "3.1 Train Dataset\n\nd_train <- read_tsv(\"C:/Users/sapi-/OneDrive/Studium/5. Semester/Data Science II/Data_Science_Blog/daten/germeval2018.training.txt\", col_names = FALSE)\n\n\nRename Columns\n\nnames(d_train) <- c(\"text\", \"c1\", \"c2\")\n\n\n\nAdd ID Column\n\nd_train <- d_train %>%\nmutate(id = row_number()) %>%\nselect(id, everything())"
  },
  {
    "objectID": "posts/Text-Mining_NEW/index.html#test-dataset",
    "href": "posts/Text-Mining_NEW/index.html#test-dataset",
    "title": "Text Mining",
    "section": "3.2 Test Dataset",
    "text": "3.2 Test Dataset\n\nd_test <- read_tsv(\"C:/Users/sapi-/OneDrive/Studium/5. Semester/Data Science II/Data_Science_Blog/daten/germeval2018.test.txt\", col_names = FALSE)\n\n\nRename Columns\n\nnames(d_test) <- c(\"text\", \"c1\", \"c2\")\n\n\n\nAdd ID Column\n\nd_test <- d_test %>%\nmutate(id = row_number()) %>%\nselect(id, everything())"
  },
  {
    "objectID": "posts/Text-Mining_NEW/index.html#show-the-important-words",
    "href": "posts/Text-Mining_NEW/index.html#show-the-important-words",
    "title": "Text Mining Analysis",
    "section": "Show The Important Words",
    "text": "Show The Important Words\n\ntrain_toc2 <- train_toc2 %>%\ncount(token, sort = TRUE)\n\n\nPlot\n\ntrain_toc2 %>%\nslice_head(n=20) %>%\nggplot()+\naes(y=reorder(factor(token), n), x = n, color = token)+\ngeom_col(aes(fill = token, alpha = 2.5)) +\nggtitle(\"The Most Used Words\") +\nylab(\"Token\")+\nxlab(\"Quantity\")+\ntheme_minimal()+\ntheme(legend.position = \"none\")\n\n\n\n\n\nWe see that the most used word is ‚Äúlbr‚Äù. We could inspect the dataset way deeper, e.g.¬†do a manual sentimentanalysis, do a lemmatization or stem the words. But we will have a look at these processes in the different machine learning algorithms following now."
  },
  {
    "objectID": "posts/Text-Mining_NEW/index.html#insert-stopwords_de",
    "href": "posts/Text-Mining_NEW/index.html#insert-stopwords_de",
    "title": "Text Mining Analysis",
    "section": "4.1 Insert Stopwords_de",
    "text": "4.1 Insert Stopwords_de\n\ndata(stopwords_de, package = \"lsa\")\nstopwords_de <- tibble(word = stopwords_de)\nstopwords_de <- stopwords_de %>%\nrename(token = word)\n\n\nAfter that we use the stopwords_de to anti_join this with train_toc dataset.\n\n\ntrain_toc2 <- train_toc %>%\nanti_join(stopwords_de)\n\nJoining, by = \"token\""
  },
  {
    "objectID": "posts/Text-Mining_NEW/index.html#define-recipe---rec1---tf-idf",
    "href": "posts/Text-Mining_NEW/index.html#define-recipe---rec1---tf-idf",
    "title": "Text Mining Analysis",
    "section": "5.1 Define Recipe - rec1 - TF-IDF",
    "text": "5.1 Define Recipe - rec1 - TF-IDF\n\nrec1 <-\nrecipe(c1 ~ ., data = select(d_train, text, c1, id)) %>%\nupdate_role(id, new_role = \"id\") %>%\nstep_tokenize(text) %>%\nstep_stopwords(text, language = \"de\", stopword_source = \"snowball\") %>%\nstep_stem(text) %>%\nstep_tfidf(text) %>%\nstep_normalize(all_numeric_predictors())\nrec1\n\nRecipe\n\nInputs:\n\n      role #variables\n        id          1\n   outcome          1\n predictor          1\n\nOperations:\n\nTokenization for text\nStop word removal for text\nStemming for text\nTerm frequency-inverse document frequency with text\nCentering and scaling for all_numeric_predictors()\n\n\n\nPrep & Bake - rec1\n\nrec1_prep <- rec1 %>%\nprep() %>%\nrecipes::bake(new_data = NULL)"
  },
  {
    "objectID": "posts/Text-Mining_NEW/index.html#define-recipe---rec2---word-embedding",
    "href": "posts/Text-Mining_NEW/index.html#define-recipe---rec2---word-embedding",
    "title": "Text Mining Analysis",
    "section": "5.2 Define Recipe - rec2 - word embedding",
    "text": "5.2 Define Recipe - rec2 - word embedding\nDue to the long calculation time and the relatively poor roc_auc values (with the training resample - v = 2, repeats = 1) , I decided not to perform the calculation for the analysis.\n\n#rec2 <-\n#recipe(c1 ~ ., data = select(d_train, text, c1, id)) %>%\n#update_role(id, new_role = \"id\") %>%\n#step_tokenize(text) %>%\n#step_stopwords(text, language = \"de\", stopword_source = \"snowball\") %>%\n#step_word_embeddings(text, embeddings = word_embedding_text)"
  },
  {
    "objectID": "posts/Text-Mining_NEW/index.html#define-recipe---rec3---word-embeddings",
    "href": "posts/Text-Mining_NEW/index.html#define-recipe---rec3---word-embeddings",
    "title": "Text Mining Analysis",
    "section": "5.3 Define Recipe - rec3 - Word Embeddings",
    "text": "5.3 Define Recipe - rec3 - Word Embeddings\n\nInsert The Helperfunctions\nWe are using the package pradadata by Sauer (2018). The data are licensed according to General Public License 3 (GLP-3).\n\ndata(\"schimpwoerter\", package = \"pradadata\")\ndata(\"sentiws\", package = \"pradadata\")\ndata(\"wild_emojis\", package = \"pradadata\")\nsource(\"C:/Users/sapi-/OneDrive/Studium/5. Semester/Data Science II/Data_Science_Blog/helper/helper_funs.R\")\n\n\n\nInsert The Predefined Word Embedding List\nThe used word embeddings are from Grave et al. (2018). The data are licensed according to Attribution-ShareAlike 3.0 Unported (CC-BY-SA 3.0).\n\nout_file_model <- \"C:/Users/sapi-/OneDrive - Hochschule f√ºr Angewandte Wissenschaften Ansbach/Desktop/AWM/angewandte Wirtschats- und Medienpsychologie/5. Semester/Word_Embedding/de.300.bin\"\n\n\nfile.exists(out_file_model)\n\n[1] TRUE\n\n\n\nfasttext_model <- load_model(out_file_model)\ndictionary <- get_dictionary(fasttext_model)\nget_word_vectors(fasttext_model, c(\"menschen\")) %>% `[`(1:10)\n\n [1] -0.043737594 -0.033647023 -0.016398411  0.037433818  0.029863771\n [6] -0.008217440  0.002691153 -0.027484305 -0.058012061  0.004103063\n\n\n\nprint(head(dictionary, 10))\n\n [1] \",\"    \".\"    \"</s>\" \"und\"  \"der\"  \":\"    \"die\"  \"\\\"\"   \")\"    \"(\"   \n\n\n\nword_embedding_text <- tibble(word = dictionary)\n\n\noptions(mc.cores = parallel::detectCores())\nwords_vecs <- get_word_vectors(fasttext_model)\n\n\nword_embedding_text <-\nword_embedding_text %>%\nbind_cols(words_vecs)\n\n\nnames(word_embedding_text) <- c(\"word\", paste0(\"v\", sprintf(\"%03d\", 1:301)))\n\n\n\nrec3\n\nrec3 <-\nrecipe(c1 ~., data = select(d_train, text, c1, id)) %>%\nupdate_role(id, new_role = \"id\") %>%\nstep_text_normalization(text) %>%\nstep_mutate(emo_count = map_int(text, ~count_lexicon(.x, sentiws$word))) %>%\nstep_mutate(schimpf_count = map_int(text, ~count_lexicon(.x, schimpfwoerter$word))) %>%\nstep_mutate(wild_emojis = map_int(text, ~count_lexicon(.x, wild_emojis$emoji))) %>%\nstep_mutate(text_copy = text) %>%\nstep_textfeature(text_copy) %>%\nstep_tokenize(text) %>%\nstep_stopwords(text, language = \"de\", stopword_source = \"snowball\") %>%\nstep_stem(text) %>%\nstep_word_embeddings(text, embeddings = word_embedding_text)\n\n\n\nPrep & Bake - rec3\n\nrec3_prep <- rec3 %>%\nprep() %>%\nrecipes::bake(new_data = NULL)"
  },
  {
    "objectID": "posts/Text-Mining_NEW/index.html#define-recipe---rec4---tf-idf",
    "href": "posts/Text-Mining_NEW/index.html#define-recipe---rec4---tf-idf",
    "title": "Text Mining Analysis",
    "section": "5.4 Define Recipe - rec4 - TF-IDF",
    "text": "5.4 Define Recipe - rec4 - TF-IDF\n\nrec4\n\nrec4 <-\nrecipe(c1 ~., data = select(d_train, text, c1, id)) %>%\nupdate_role(id, new_role = \"id\") %>% \nstep_text_normalization(text) %>%\nstep_mutate(emo_count = map_int(text, ~count_lexicon(.x, sentiws$word))) %>%\nstep_mutate(schimpf_count = map_int(text, ~count_lexicon(.x, schimpfwoerter$word))) %>%\nstep_mutate(wild_emojis = map_int(text, ~count_lexicon(.x, wild_emojis$emoji))) %>%\nstep_mutate(text_copy = text) %>%\nstep_textfeature(text_copy) %>%\nstep_tokenize(text) %>%\nstep_stopwords(text, language = \"de\", stopword_source = \"snowball\") %>%\nstep_stem(text) %>%\nstep_tfidf(text)\n\n\n\nPrep & Bake - rec4\n\nrec4_prep <- rec4 %>%\nprep() %>%\nrecipes::bake(new_data = NULL)"
  },
  {
    "objectID": "posts/Text-Mining_NEW/index.html#null-model",
    "href": "posts/Text-Mining_NEW/index.html#null-model",
    "title": "Text Mining Analysis",
    "section": "8.1 Null Model",
    "text": "8.1 Null Model"
  },
  {
    "objectID": "posts/Text-Mining_NEW/index.html#lasso-l1-with-tf-idf",
    "href": "posts/Text-Mining_NEW/index.html#lasso-l1-with-tf-idf",
    "title": "Text Mining Analysis",
    "section": "8.2 Lasso-L1 With TF-IDF",
    "text": "8.2 Lasso-L1 With TF-IDF\nAccording to the large amount of data, I decided to not run the Null Model and the L1-TF-IDF with rec1."
  },
  {
    "objectID": "posts/Text-Mining_NEW/index.html#ridge-regression-l2-with-tf-idf",
    "href": "posts/Text-Mining_NEW/index.html#ridge-regression-l2-with-tf-idf",
    "title": "Text Mining Analysis",
    "section": "8.3 Ridge-Regression-L2 With TF-IDF",
    "text": "8.3 Ridge-Regression-L2 With TF-IDF\n\nL2-Model\n\nl2_83_mod <- logistic_reg(penalty = tune(), mixture = 0) %>%\nset_engine(\"glmnet\") %>%\nset_mode(\"classification\")\nl2_83_mod\n\nLogistic Regression Model Specification (classification)\n\nMain Arguments:\n  penalty = tune()\n  mixture = 0\n\nComputational engine: glmnet \n\n\n\n\nDefine The Workflow\n\nl2_83_wf <-workflow() %>%\nadd_recipe(rec1) %>%\nadd_model(l2_83_mod)\nl2_83_wf\n\n== Workflow ====================================================================\nPreprocessor: Recipe\nModel: logistic_reg()\n\n-- Preprocessor ----------------------------------------------------------------\n5 Recipe Steps\n\n* step_tokenize()\n* step_stopwords()\n* step_stem()\n* step_tfidf()\n* step_normalize()\n\n-- Model -----------------------------------------------------------------------\nLogistic Regression Model Specification (classification)\n\nMain Arguments:\n  penalty = tune()\n  mixture = 0\n\nComputational engine: glmnet \n\n\n\n\nResampling & Model Quality\n\noptions(mc.cores = parallel::detectCores())\nl2_83_wf_fit <- tune_grid(\nl2_83_wf,\nfolds,\ngrid = lambda_grid,\ncontrol = control_resamples(save_pred = TRUE)\n)\n\nWarning: Paket 'stopwords' wurde unter R Version 4.1.3 erstellt\n\n\nWarning: Paket 'glmnet' wurde unter R Version 4.1.3 erstellt\n\n\nWarning: Paket 'Matrix' wurde unter R Version 4.1.3 erstellt\n\n\nx Fold3, Repeat1: preprocessor 1/1, model 1/1: Error: kann Vektor der Gr√∂√üe 324.7 MB nicht allozieren\n\n\n\n\nModel Performance\n\nl2_83_wf_fit_performance <- collect_metrics(l2_83_wf_fit)\nl2_83_wf_fit_performance\n\n# A tibble: 50 x 7\n    penalty .metric  .estimator  mean     n std_err .config              \n      <dbl> <chr>    <chr>      <dbl> <int>   <dbl> <chr>                \n 1 1   e-10 accuracy binary     0.708     5 0.00370 Preprocessor1_Model01\n 2 1   e-10 roc_auc  binary     0.756     5 0.00603 Preprocessor1_Model01\n 3 2.61e-10 accuracy binary     0.708     5 0.00370 Preprocessor1_Model02\n 4 2.61e-10 roc_auc  binary     0.756     5 0.00603 Preprocessor1_Model02\n 5 6.81e-10 accuracy binary     0.708     5 0.00370 Preprocessor1_Model03\n 6 6.81e-10 roc_auc  binary     0.756     5 0.00603 Preprocessor1_Model03\n 7 1.78e- 9 accuracy binary     0.708     5 0.00370 Preprocessor1_Model04\n 8 1.78e- 9 roc_auc  binary     0.756     5 0.00603 Preprocessor1_Model04\n 9 4.64e- 9 accuracy binary     0.708     5 0.00370 Preprocessor1_Model05\n10 4.64e- 9 roc_auc  binary     0.756     5 0.00603 Preprocessor1_Model05\n# ... with 40 more rows\n\n\n\nl2_83_wf_fit_preds <- collect_predictions(l2_83_wf_fit)\n\n\nl2_83_wf_fit_preds %>% \n  group_by(id) %>% \n  roc_curve(truth = c1, .pred_OFFENSE) %>% \n  autoplot()\n\n\n\n\n\nThere is a small difference between both repetitions.\n\n\n\nSelect The Best\n\nchosen_auc_l2_83_wf_fit <-\nl2_83_wf_fit %>%\nselect_by_one_std_err(metric = \"roc_auc\", -penalty)\nchosen_auc_l2_83_wf_fit\n\n# A tibble: 1 x 9\n  penalty .metric .estimator  mean     n std_err .config            .best .bound\n    <dbl> <chr>   <chr>      <dbl> <int>   <dbl> <chr>              <dbl>  <dbl>\n1       1 roc_auc binary     0.757     5 0.00593 Preprocessor1_Mod~ 0.757  0.751\n\n\n\n\nPositive Predictive Value\n\nppv(l2_83_wf_fit_preds, truth = factor(c1), estimate = .pred_class)\n\n# A tibble: 1 x 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 ppv     binary         0.638"
  },
  {
    "objectID": "posts/Text-Mining_NEW/index.html#lasso-l1-with-word-embeddings",
    "href": "posts/Text-Mining_NEW/index.html#lasso-l1-with-word-embeddings",
    "title": "Text Mining Analysis",
    "section": "8.4 Lasso-L1 With Word Embeddings",
    "text": "8.4 Lasso-L1 With Word Embeddings\nLike the Null Model (8.1) and the L1 with TF-IDF (8.2) I decided to kick the L1 with Word Embeddings out of the analysis, because the results in the training phase were too poor, to use it in the prediction phase."
  },
  {
    "objectID": "posts/Text-Mining_NEW/index.html#ridge-regression-l2-with-tf-idf-1",
    "href": "posts/Text-Mining_NEW/index.html#ridge-regression-l2-with-tf-idf-1",
    "title": "Text Mining Analysis",
    "section": "8.5 Ridge-Regression-L2 with TF-IDF",
    "text": "8.5 Ridge-Regression-L2 with TF-IDF\n\nL2-Model\n\nl2_85_mod <- logistic_reg(penalty = tune(), mixture = 0) %>%\nset_engine(\"glmnet\") %>%\nset_mode(\"classification\")\nl2_85_mod\n\nLogistic Regression Model Specification (classification)\n\nMain Arguments:\n  penalty = tune()\n  mixture = 0\n\nComputational engine: glmnet \n\n\n\n\nDefine The Workflow\n\nl2_85_wf <-workflow() %>%\nadd_recipe(rec3) %>%\nadd_model(l2_85_mod)\nl2_85_wf\n\n== Workflow ====================================================================\nPreprocessor: Recipe\nModel: logistic_reg()\n\n-- Preprocessor ----------------------------------------------------------------\n10 Recipe Steps\n\n* step_text_normalization()\n* step_mutate()\n* step_mutate()\n* step_mutate()\n* step_mutate()\n* step_textfeature()\n* step_tokenize()\n* step_stopwords()\n* step_stem()\n* step_word_embeddings()\n\n-- Model -----------------------------------------------------------------------\nLogistic Regression Model Specification (classification)\n\nMain Arguments:\n  penalty = tune()\n  mixture = 0\n\nComputational engine: glmnet \n\n\n\n\nResampling & Model Quality\n\noptions(mc.cores = parallel::detectCores())\nl2_85_wf_fit <- tune_grid(\nl2_85_wf,\nfolds,\ngrid = lambda_grid,\ncontrol = control_resamples(save_pred = TRUE)\n)\n\nWarning: Paket 'stringi' wurde unter R Version 4.1.2 erstellt\n\n\nWarning: Paket 'textfeatures' wurde unter R Version 4.1.3 erstellt\n\n\n\n\nModel Performance\n\nl2_85_wf_performance <- collect_metrics(l2_85_wf_fit)\nl2_85_wf_performance\n\n# A tibble: 50 x 7\n    penalty .metric  .estimator  mean     n std_err .config              \n      <dbl> <chr>    <chr>      <dbl> <int>   <dbl> <chr>                \n 1 1   e-10 accuracy binary     0.736     6 0.00297 Preprocessor1_Model01\n 2 1   e-10 roc_auc  binary     0.763     6 0.00295 Preprocessor1_Model01\n 3 2.61e-10 accuracy binary     0.736     6 0.00297 Preprocessor1_Model02\n 4 2.61e-10 roc_auc  binary     0.763     6 0.00295 Preprocessor1_Model02\n 5 6.81e-10 accuracy binary     0.736     6 0.00297 Preprocessor1_Model03\n 6 6.81e-10 roc_auc  binary     0.763     6 0.00295 Preprocessor1_Model03\n 7 1.78e- 9 accuracy binary     0.736     6 0.00297 Preprocessor1_Model04\n 8 1.78e- 9 roc_auc  binary     0.763     6 0.00295 Preprocessor1_Model04\n 9 4.64e- 9 accuracy binary     0.736     6 0.00297 Preprocessor1_Model05\n10 4.64e- 9 roc_auc  binary     0.763     6 0.00295 Preprocessor1_Model05\n# ... with 40 more rows\n\n\n\nl2_85_wf_fit_preds <- collect_predictions(l2_85_wf_fit)\n\n\nl2_85_wf_fit_preds %>% \n  group_by(id) %>% \n  roc_curve(truth = c1, .pred_OFFENSE) %>% \n  autoplot()\n\n\n\n\n\n\nSelect The Best\n\nchosen_auc_l2_85_wf_fit <-\nl2_85_wf_fit %>%\nselect_by_one_std_err(metric = \"roc_auc\", -penalty)\nchosen_auc_l2_85_wf_fit\n\n# A tibble: 1 x 9\n  penalty .metric .estimator  mean     n std_err .config            .best .bound\n    <dbl> <chr>   <chr>      <dbl> <int>   <dbl> <chr>              <dbl>  <dbl>\n1   0.147 roc_auc binary     0.767     6 0.00378 Preprocessor1_Mod~ 0.768  0.764\n\n\n\nconf_mat_resampled(l2_85_wf_fit, tidy = FALSE, parameter = select_best(l2_85_wf_fit)) %>% \n  autoplot(type = \"heatmap\") \n\nWarning: No value of `metric` was given; metric 'roc_auc' will be used.\n\n\n\n\n\n\n\nPositive Predictive Value\n\nppv(l2_85_wf_fit_preds, truth = factor(c1), estimate = .pred_class)\n\n# A tibble: 1 x 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 ppv     binary         0.667"
  },
  {
    "objectID": "posts/Text-Mining_NEW/index.html#lasso-l1-with-tf-idf-1",
    "href": "posts/Text-Mining_NEW/index.html#lasso-l1-with-tf-idf-1",
    "title": "Text Mining Analysis",
    "section": "8.6 Lasso-L1 With TF-IDF",
    "text": "8.6 Lasso-L1 With TF-IDF\n\nL1-Model\n\nl1_86_mod <- logistic_reg(penalty = tune(), mixture = 1) %>%\nset_engine(\"glmnet\") %>%\nset_mode(\"classification\")\nl1_86_mod\n\nLogistic Regression Model Specification (classification)\n\nMain Arguments:\n  penalty = tune()\n  mixture = 1\n\nComputational engine: glmnet \n\n\n\n\nDefine The Workflow\n\nl1_86_wf <-workflow() %>%\nadd_recipe(rec4) %>%\nadd_model(l1_86_mod)\nl1_86_wf\n\n== Workflow ====================================================================\nPreprocessor: Recipe\nModel: logistic_reg()\n\n-- Preprocessor ----------------------------------------------------------------\n10 Recipe Steps\n\n* step_text_normalization()\n* step_mutate()\n* step_mutate()\n* step_mutate()\n* step_mutate()\n* step_textfeature()\n* step_tokenize()\n* step_stopwords()\n* step_stem()\n* step_tfidf()\n\n-- Model -----------------------------------------------------------------------\nLogistic Regression Model Specification (classification)\n\nMain Arguments:\n  penalty = tune()\n  mixture = 1\n\nComputational engine: glmnet \n\n\n\n\nResampling & Model Quality\n\noptions(mc.cores = parallel::detectCores())\ntic()\nl1_86_wf_fit <- tune_grid(\nl1_86_wf,\nfolds,\ngrid = lambda_grid,\ncontrol = control_resamples(save_pred = TRUE)\n)\ntoc()\n\n1227.83 sec elapsed\n\n\n\n\nModel Performance\n\nl1_86_wf_performance <- collect_metrics(l1_86_wf_fit)\nl1_86_wf_performance\n\n# A tibble: 50 x 7\n    penalty .metric  .estimator  mean     n std_err .config              \n      <dbl> <chr>    <chr>      <dbl> <int>   <dbl> <chr>                \n 1 1   e-10 accuracy binary     0.748     6 0.00200 Preprocessor1_Model01\n 2 1   e-10 roc_auc  binary     0.774     6 0.00204 Preprocessor1_Model01\n 3 2.61e-10 accuracy binary     0.748     6 0.00200 Preprocessor1_Model02\n 4 2.61e-10 roc_auc  binary     0.774     6 0.00204 Preprocessor1_Model02\n 5 6.81e-10 accuracy binary     0.748     6 0.00200 Preprocessor1_Model03\n 6 6.81e-10 roc_auc  binary     0.774     6 0.00204 Preprocessor1_Model03\n 7 1.78e- 9 accuracy binary     0.748     6 0.00200 Preprocessor1_Model04\n 8 1.78e- 9 roc_auc  binary     0.774     6 0.00204 Preprocessor1_Model04\n 9 4.64e- 9 accuracy binary     0.748     6 0.00200 Preprocessor1_Model05\n10 4.64e- 9 roc_auc  binary     0.774     6 0.00204 Preprocessor1_Model05\n# ... with 40 more rows\n\n\n\nl1_86_wf_fit_preds <- collect_predictions(l1_86_wf_fit)\n\n\nl1_86_wf_fit_preds %>% \n  group_by(id) %>% \n  roc_curve(truth = c1, .pred_OFFENSE) %>% \n  autoplot()\n\n\n\n\n\nIt looks like Repeat1 is a little bit better because the line is bent more towards sensitivity.\n\n\nconf_mat_resampled(l1_86_wf_fit, tidy = FALSE, parameter = select_best(l1_86_wf_fit)) %>% \n  autoplot(type = \"heatmap\") \n\nWarning: No value of `metric` was given; metric 'roc_auc' will be used.\n\n\n\n\n\n\n\nSelect The Best\n\nchosen_auc_l1_86_wf_fit <-\nl1_86_wf_fit %>%\nselect_by_one_std_err(metric = \"roc_auc\", -penalty)\nchosen_auc_l1_86_wf_fit\n\n# A tibble: 1 x 9\n  penalty .metric .estimator  mean     n std_err .config            .best .bound\n    <dbl> <chr>   <chr>      <dbl> <int>   <dbl> <chr>              <dbl>  <dbl>\n1 0.00825 roc_auc binary     0.784     6 0.00471 Preprocessor1_Mod~ 0.784  0.780\n\n\n\n\nPositive Predictive Value\n\nppv(l1_86_wf_fit_preds, truth = factor(c1), estimate = .pred_class)\n\n# A tibble: 1 x 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 ppv     binary         0.677"
  },
  {
    "objectID": "posts/Text-Mining_NEW/index.html#ridge-regression-l2-with-tf-idf-2",
    "href": "posts/Text-Mining_NEW/index.html#ridge-regression-l2-with-tf-idf-2",
    "title": "Text Mining Analysis",
    "section": "8.7 Ridge-Regression-L2 With TF-IDF",
    "text": "8.7 Ridge-Regression-L2 With TF-IDF\n\nL2-Model\n\nl2_87_mod <- logistic_reg(penalty = tune(), mixture = 0) %>%\nset_engine(\"glmnet\") %>%\nset_mode(\"classification\")\nl2_87_mod\n\nLogistic Regression Model Specification (classification)\n\nMain Arguments:\n  penalty = tune()\n  mixture = 0\n\nComputational engine: glmnet \n\n\n\n\nDefine The Workflow\n\nl2_87_wf <-workflow() %>%\nadd_recipe(rec4) %>%\nadd_model(l2_87_mod)\nl2_87_wf\n\n== Workflow ====================================================================\nPreprocessor: Recipe\nModel: logistic_reg()\n\n-- Preprocessor ----------------------------------------------------------------\n10 Recipe Steps\n\n* step_text_normalization()\n* step_mutate()\n* step_mutate()\n* step_mutate()\n* step_mutate()\n* step_textfeature()\n* step_tokenize()\n* step_stopwords()\n* step_stem()\n* step_tfidf()\n\n-- Model -----------------------------------------------------------------------\nLogistic Regression Model Specification (classification)\n\nMain Arguments:\n  penalty = tune()\n  mixture = 0\n\nComputational engine: glmnet \n\n\n\n\nResampling & Model Quality\n\noptions(mc.cores = parallel::detectCores())\nl2_87_wf_fit <- tune_grid(\nl2_87_wf,\nfolds,\ngrid = lambda_grid,\ncontrol = control_resamples(save_pred = TRUE)\n)\n\n\n\nModel Performance\n\nl2_87_wf_performance <- collect_metrics(l2_87_wf_fit)\nl2_87_wf_performance\n\n# A tibble: 50 x 7\n    penalty .metric  .estimator  mean     n std_err .config              \n      <dbl> <chr>    <chr>      <dbl> <int>   <dbl> <chr>                \n 1 1   e-10 accuracy binary     0.703     6 0.00190 Preprocessor1_Model01\n 2 1   e-10 roc_auc  binary     0.768     6 0.00502 Preprocessor1_Model01\n 3 2.61e-10 accuracy binary     0.703     6 0.00190 Preprocessor1_Model02\n 4 2.61e-10 roc_auc  binary     0.768     6 0.00502 Preprocessor1_Model02\n 5 6.81e-10 accuracy binary     0.703     6 0.00190 Preprocessor1_Model03\n 6 6.81e-10 roc_auc  binary     0.768     6 0.00502 Preprocessor1_Model03\n 7 1.78e- 9 accuracy binary     0.703     6 0.00190 Preprocessor1_Model04\n 8 1.78e- 9 roc_auc  binary     0.768     6 0.00502 Preprocessor1_Model04\n 9 4.64e- 9 accuracy binary     0.703     6 0.00190 Preprocessor1_Model05\n10 4.64e- 9 roc_auc  binary     0.768     6 0.00502 Preprocessor1_Model05\n# ... with 40 more rows\n\n\n\nl2_87_wf_fit_preds <- collect_predictions(l2_87_wf_fit)\n\n\nl2_87_wf_fit_preds %>% \n  group_by(id) %>% \n  roc_curve(truth = c1, .pred_OFFENSE) %>% \n  autoplot()\n\n\n\n\n\n\nSelect The Best\n\nchosen_auc_l2_87_wf_fit <-\nl2_87_wf_fit %>%\nselect_by_one_std_err(metric = \"roc_auc\", -penalty)\nchosen_auc_l2_87_wf_fit\n\n# A tibble: 1 x 9\n  penalty .metric .estimator  mean     n std_err .config            .best .bound\n    <dbl> <chr>   <chr>      <dbl> <int>   <dbl> <chr>              <dbl>  <dbl>\n1       1 roc_auc binary     0.768     6 0.00502 Preprocessor1_Mod~ 0.768  0.763\n\n\n\nconf_mat_resampled(l2_87_wf_fit, tidy = FALSE, parameter = select_best(l2_87_wf_fit)) %>% \n  autoplot(type = \"heatmap\") \n\nWarning: No value of `metric` was given; metric 'roc_auc' will be used.\n\n\n\n\n\n\n\nPositive Predictive Value\n\nppv(l2_87_wf_fit_preds, truth = factor(c1), estimate = .pred_class)\n\n# A tibble: 1 x 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 ppv     binary         0.665"
  },
  {
    "objectID": "posts/Text-Mining_Solutions/index.html",
    "href": "posts/Text-Mining_Solutions/index.html",
    "title": "Text Mining Solution",
    "section": "",
    "text": "For this analysis we use the dataset from Wiegand (2019a) out of the zip archive Wiegand (2019b). The data are licensed according to Attribution 4.0 International (CC-BY-4.0).\nThe welcome page picture, to this post is from talha khalil at Pixabay\n\n\n\nThe United Nations defines hate speech as: ‚Äúany kind of communication in speech, writing or behaviour, that attacks or uses pejorative or discriminatory language with reference to a person or a group on the basis of who they are, in other words, based on their religion, ethnicity, nationality, race, colour, descent, gender or other identity factor.‚Äù\nThe problem about hate speech is, that there is no universal definition that can be used.\nSo our research question is, if there is any possibility to predict hate speech by using tweets and how well is the prediction?"
  },
  {
    "objectID": "posts/Text-Mining_Solutions/index.html#train-dataset",
    "href": "posts/Text-Mining_Solutions/index.html#train-dataset",
    "title": "Text Mining Solution",
    "section": "3.1 Train Dataset",
    "text": "3.1 Train Dataset\n\nd_train <- read_tsv(\"C:/Users/sapi-/OneDrive/Studium/5. Semester/Data Science II/Data_Science_Blog/daten/germeval2018.training.txt\", col_names = FALSE)\n\n\nRename Columns\n\nnames(d_train) <- c(\"text\", \"c1\", \"c2\")\n\n\n\nAdd ID Column\n\nd_train <- d_train %>%\nmutate(id = row_number()) %>%\nselect(id, everything())"
  },
  {
    "objectID": "posts/Text-Mining_Solutions/index.html#test-dataset",
    "href": "posts/Text-Mining_Solutions/index.html#test-dataset",
    "title": "Text Mining Solution",
    "section": "3.2 Test Dataset",
    "text": "3.2 Test Dataset\n\nd_test <- read_tsv(\"C:/Users/sapi-/OneDrive/Studium/5. Semester/Data Science II/Data_Science_Blog/daten/germeval2018.test.txt\", col_names = FALSE)\n\n\nRename Columns\n\nnames(d_test) <- c(\"text\", \"c1\", \"c2\")\n\n\n\nAdd ID Column\n\nd_test <- d_test %>%\nmutate(id = row_number()) %>%\nselect(id, everything())"
  },
  {
    "objectID": "posts/Text-Mining_Solutions/index.html#lasso-l1-with-tf-idf",
    "href": "posts/Text-Mining_Solutions/index.html#lasso-l1-with-tf-idf",
    "title": "Text Mining Solution",
    "section": "10. Lasso-L1 With TF-IDF",
    "text": "10. Lasso-L1 With TF-IDF\n\nL1-Model\n\nl1_86_mod <- logistic_reg(penalty = tune(), mixture = 1) %>%\nset_engine(\"glmnet\") %>%\nset_mode(\"classification\")\nl1_86_mod\n\nLogistic Regression Model Specification (classification)\n\nMain Arguments:\n  penalty = tune()\n  mixture = 1\n\nComputational engine: glmnet \n\n\n\n\nDefine The Workflow\n\nl1_86_wf <-workflow() %>%\nadd_recipe(rec4) %>%\nadd_model(l1_86_mod)\nl1_86_wf\n\n== Workflow ====================================================================\nPreprocessor: Recipe\nModel: logistic_reg()\n\n-- Preprocessor ----------------------------------------------------------------\n10 Recipe Steps\n\n* step_text_normalization()\n* step_mutate()\n* step_mutate()\n* step_mutate()\n* step_mutate()\n* step_textfeature()\n* step_tokenize()\n* step_stopwords()\n* step_stem()\n* step_tfidf()\n\n-- Model -----------------------------------------------------------------------\nLogistic Regression Model Specification (classification)\n\nMain Arguments:\n  penalty = tune()\n  mixture = 1\n\nComputational engine: glmnet \n\n\n\n\nResampling & Model Quality\n\noptions(mc.cores = parallel::detectCores())\ntic()\nl1_86_wf_fit <- tune_grid(\nl1_86_wf,\nfolds,\ngrid = lambda_grid,\ncontrol = control_resamples(save_pred = TRUE)\n)\n\nWarning: Paket 'stringi' wurde unter R Version 4.1.2 erstellt\n\n\nWarning: Paket 'textfeatures' wurde unter R Version 4.1.3 erstellt\n\n\nWarning: Paket 'stopwords' wurde unter R Version 4.1.3 erstellt\n\n\nWarning: Paket 'glmnet' wurde unter R Version 4.1.3 erstellt\n\n\nWarning: Paket 'Matrix' wurde unter R Version 4.1.3 erstellt\n\ntoc()\n\n392.08 sec elapsed\n\n\n\n\nModel Performance\n\nl1_86_wf_performance <- collect_metrics(l1_86_wf_fit)\nl1_86_wf_performance\n\n# A tibble: 40 x 7\n    penalty .metric  .estimator  mean     n std_err .config              \n      <dbl> <chr>    <chr>      <dbl> <int>   <dbl> <chr>                \n 1 1   e-10 accuracy binary     0.742     3 0.00273 Preprocessor1_Model01\n 2 1   e-10 roc_auc  binary     0.774     3 0.00355 Preprocessor1_Model01\n 3 3.36e-10 accuracy binary     0.742     3 0.00273 Preprocessor1_Model02\n 4 3.36e-10 roc_auc  binary     0.774     3 0.00355 Preprocessor1_Model02\n 5 1.13e- 9 accuracy binary     0.742     3 0.00273 Preprocessor1_Model03\n 6 1.13e- 9 roc_auc  binary     0.774     3 0.00355 Preprocessor1_Model03\n 7 3.79e- 9 accuracy binary     0.742     3 0.00273 Preprocessor1_Model04\n 8 3.79e- 9 roc_auc  binary     0.774     3 0.00355 Preprocessor1_Model04\n 9 1.27e- 8 accuracy binary     0.742     3 0.00273 Preprocessor1_Model05\n10 1.27e- 8 roc_auc  binary     0.774     3 0.00355 Preprocessor1_Model05\n# ... with 30 more rows\n\n\n\nl1_86_wf_fit_preds <- collect_predictions(l1_86_wf_fit)\n\n\nl1_86_wf_fit_preds %>% \n  group_by(id) %>% \n  roc_curve(truth = c1, .pred_OFFENSE) %>% \n  autoplot()\n\n\n\n\n\n\nSelect The Best\n\nchosen_auc_l1_86_wf_fit <-\nl1_86_wf_fit %>%\nselect_by_one_std_err(metric = \"roc_auc\", -penalty)\nchosen_auc_l1_86_wf_fit\n\n# A tibble: 1 x 9\n  penalty .metric .estimator  mean     n std_err .config            .best .bound\n    <dbl> <chr>   <chr>      <dbl> <int>   <dbl> <chr>              <dbl>  <dbl>\n1 0.00785 roc_auc binary     0.787     3 0.00208 Preprocessor1_Mod~ 0.787  0.785"
  },
  {
    "objectID": "posts/Text-Mining_Solutions/index.html#finalize-the-workflow",
    "href": "posts/Text-Mining_Solutions/index.html#finalize-the-workflow",
    "title": "Text Mining Solution",
    "section": "Finalize The Workflow",
    "text": "Finalize The Workflow\n\nl1_86_wf_final <- \n  l1_86_wf %>% \n  finalize_workflow(select_best(l1_86_wf_fit, metric = \"roc_auc\"))"
  },
  {
    "objectID": "posts/Text-Mining_Solutions/index.html#adaptation-of-the-finished-workflow-to-the-training-dataset",
    "href": "posts/Text-Mining_Solutions/index.html#adaptation-of-the-finished-workflow-to-the-training-dataset",
    "title": "Text Mining Solution",
    "section": "Adaptation Of The Finished Workflow To The Training Dataset",
    "text": "Adaptation Of The Finished Workflow To The Training Dataset\n\noptions(mc.cores = parallel::detectCores())\nfit_train <- l1_86_wf_final %>% \n  fit(d_train)"
  },
  {
    "objectID": "posts/Text-Mining_Solutions/index.html#adapt-the-predictions-to-the-test-dataset",
    "href": "posts/Text-Mining_Solutions/index.html#adapt-the-predictions-to-the-test-dataset",
    "title": "Text Mining Solution",
    "section": "Adapt The Predictions To The Test Dataset",
    "text": "Adapt The Predictions To The Test Dataset\n\nfit_test <- fit_train %>% \n  predict(d_test)"
  },
  {
    "objectID": "posts/Text-Mining_Solutions/index.html#add-id-column-2",
    "href": "posts/Text-Mining_Solutions/index.html#add-id-column-2",
    "title": "Text Mining Solution",
    "section": "Add ID Column",
    "text": "Add ID Column\n\nfit_test <- fit_test %>% \n  mutate(id = row_number())"
  },
  {
    "objectID": "posts/Text-Mining_Solutions/index.html#join-both-datasets",
    "href": "posts/Text-Mining_Solutions/index.html#join-both-datasets",
    "title": "Text Mining Solution",
    "section": "Join Both Datasets",
    "text": "Join Both Datasets\n\ntest <- fit_test %>% \n  full_join(d_test, by = \"id\")\n\n\ntest <- test %>% \n  select(id, text, c1, c2, .pred_class)"
  },
  {
    "objectID": "posts/Text-Mining_Solutions/index.html#test-the-predictions",
    "href": "posts/Text-Mining_Solutions/index.html#test-the-predictions",
    "title": "Text Mining Solution",
    "section": "Test The Predictions",
    "text": "Test The Predictions\n\ntest %>% \n  count(c1, .pred_class)\n\n# A tibble: 4 x 3\n  c1      .pred_class     n\n  <chr>   <fct>       <int>\n1 OFFENSE OFFENSE       237\n2 OFFENSE OTHER         521\n3 OTHER   OFFENSE       113\n4 OTHER   OTHER        1357\n\n\n\ntest %>% \n  filter(c1 == \"OTHER\", .pred_class == \"OTHER\") %>% \n  nrow/nrow(test)\n\n[1] 0.6090664\n\n\n\ntest %>% \n  filter(c1 == \"OFFENSE\", .pred_class == \"OFFENSE\") %>% \n  nrow/nrow(test)\n\n[1] 0.1063734\n\n\n\nThe table shows us how the predictions .pred_class match the actual classified data c1.\nSo we see, that 237 OFFENSE (10,6 %) tweets are actually predicted to be OFFENSE and that 1357 (60,9 %) OTHER classified tweets are predicted to be OTHER.\nOnly 634 tweets were not predicted correctly.\n\nAccuracy\n\naccuracy(test, truth = factor(c1), estimate = .pred_class)\n\n# A tibble: 1 x 3\n  .metric  .estimator .estimate\n  <chr>    <chr>          <dbl>\n1 accuracy binary         0.715\n\n\n\nsens(test, truth = factor(c1), estimate = .pred_class)\n\n# A tibble: 1 x 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 sens    binary         0.313\n\n\n\nspec(test, truth = factor(c1), estimate = .pred_class)\n\n# A tibble: 1 x 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 spec    binary         0.923"
  }
]